{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#olist-modern-analytics-platform","title":"\ud83d\ude80 Olist Modern Analytics PlatformProduction-Style Analytics Engineering","text":"<p>Portfolio Scenario \u2022 Modern Data Stack</p> <p>Azure Blob \u2192 Snowflake \u2192 dbt \u2192 Power BI \u2192 GitHub Actions</p> <p>A portfolio platform focused on trust, governance, and measurable delivery quality across ingestion, transformation, semantic modeling, and DataOps.</p> View Architecture View Quality Framework"},{"location":"#architecture-preview","title":"\ud83c\udfd7\ufe0f Architecture Preview","text":"<p>Open full architecture view \u2192</p>"},{"location":"#platform-metrics","title":"\ud83d\udcca Platform Metrics","text":"Automated Tests 559 dbt + Source Tests dbt Models 24 Staging + Marts Data Volume 1.55M Rows Processed Dashboard Load &lt; 2s Performance SLA"},{"location":"#what-this-project-demonstrates","title":"\ud83c\udfaf What This Project Demonstrates","text":"<p>Enterprise-Grade Analytics Engineering</p> <p>End-to-end modern data stack implementation with production-quality standards:</p> <pre><code>\u2705 **Architecture:** Clear layer boundaries (RAW \u2192 STAGING \u2192 INTERMEDIATE \u2192 MARTS)\n\u2705 **Quality:** 559 automated tests with 100% data quality score\n\u2705 **DataOps:** CI/CD pipelines with automated testing and deployment\n\u2705 **Performance:** Sub-2-second dashboard loads with cost optimization\n\u2705 **Governance:** Row-level security (RLS), data contracts, semantic layer\n\u2705 **Documentation:** Comprehensive docs with screenshots and evidence\n</code></pre>"},{"location":"#technology-stack","title":"\ud83c\udfd7\ufe0f Technology Stack","text":"\u2601\ufe0f Azure Blob Storage Centralized data lake for raw CSV/JSON/Parquet files \u2744\ufe0f Snowflake Cloud data warehouse with auto-suspend &amp; resource monitors \ud83d\udd27 dbt Core Data transformation with star schema modeling &amp; testing \ud83d\udcca Power BI Semantic model with RLS, incremental refresh &amp; BPA validation \ud83e\udd16 GitHub Actions CI/CD pipelines for dbt tests &amp; SQLFluff linting \ud83e\udde0 AI-Assisted Dev GitHub Copilot + ChatGPT with human validation"},{"location":"#documentation-navigator","title":"\ud83d\udcda Documentation Navigator","text":""},{"location":"#core-design-documents","title":"\ud83d\udccb Core Design Documents","text":"\ud83c\udfaf Business Requirements KPI definitions, business questions, success criteria \ud83c\udfdb\ufe0f Architecture System design, data flow, layer responsibilities \ud83d\udcd6 Data Dictionary Schema definitions, business rules, grain documentation"},{"location":"#implementation-quality","title":"\u2705 Implementation Quality","text":"\ud83e\uddea Data Quality Framework 559 automated tests, validation strategy, quality gates \u26a1 Performance Optimization Cost controls, incremental refresh, query optimization \ud83d\udee0\ufe0f Engineering Standards ADLC framework, DataOps, AI-assisted development"},{"location":"#bi-analytics","title":"\ud83d\udcca BI &amp; Analytics","text":"\ud83e\udde0 Semantic Model Power BI measures, RLS implementation, DAX patterns \ud83d\udcc8 Analytics Insights Business findings, KPI analysis, recommendations"},{"location":"#adlc-5-phase-journey","title":"\ud83d\uddfa\ufe0f ADLC 5-Phase Journey","text":"<p>Structured Development Lifecycle</p> <p>This project follows the Analytics Development Life Cycle (ADLC) framework for organized, phase-gated delivery:</p> Phase Focus Area Key Deliverables Status Phase 1 Requirements &amp; Planning Business questions, KPI definitions, architecture design \u2705 Complete Phase 2 Data Ingestion Azure Blob setup, Snowflake RAW layer (1.55M rows) \u2705 Complete Phase 3 Transformation dbt models (staging \u2192 marts), star schema \u2705 Complete Phase 4 DataOps &amp; CI/CD GitHub Actions, automated testing (559 tests) \u2705 Complete Phase 5 BI &amp; Semantic Layer Power BI semantic model, dashboards, RLS \u2705 Complete"},{"location":"#key-capabilities","title":"\ud83c\udfc6 Key Capabilities","text":"<p>What Sets This Project Apart</p> <p>\ud83d\udd12 Governance-First Design</p> <ul> <li>Row-level security (RLS) with dynamic bridge pattern</li> <li>Data contracts enforce schema validation</li> <li>Certified semantic layer prevents metric chaos</li> </ul> <p>\ud83e\uddea Quality-Driven Development</p> <ul> <li>559 automated tests (85 source + 474 model tests)</li> <li>100% data quality score validated</li> <li>CI gates prevent bad data from reaching production</li> </ul> <p>\ud83d\udcb0 Cost-Optimized Architecture</p> <ul> <li>Snowflake auto-suspend (60s/300s) saves compute costs</li> <li>Power BI incremental refresh reduces load times</li> <li>Query tagging enables cost attribution</li> </ul> <p>\ud83e\udd16 AI-Accelerated Development</p> <ul> <li>GitHub Copilot integration with custom instructions</li> <li>ChatGPT project with full context management</li> <li>Human validation for all AI-generated code</li> </ul>"},{"location":"#external-links","title":"\ud83d\udd17 External Links","text":"<ul> <li>GitHub Repository: AyanMulaskar223/olist-modern-analytics-platform</li> <li>LinkedIn: Connect with Ayan Mulaskar</li> </ul> <p> Built with \u2764\ufe0f using the Modern Data Stack \u2022 February 2026 </p>"},{"location":"00_business_requirements/","title":"Biz Requirements","text":""},{"location":"00_business_requirements/#phase-1-business-requirements-document-brd","title":"\ud83c\udfaf Phase 1: Business Requirements Document (BRD)","text":""},{"location":"00_business_requirements/#executive-summary","title":"\ud83d\udcca Executive Summary","text":"<p>Olist's fragmented analytics ecosystem prevents leadership from making fast, confident data-driven decisions. Sales, Finance, and Operations teams report conflicting revenue numbers, lack visibility into delivery bottlenecks, and spend 4+ days monthly reconciling spreadsheets.</p> <p>This Modern Data Stack initiative establishes a single source of truth using Snowflake, dbt, and Power BI to standardize KPIs, reduce insight latency from weekly to daily, and enable self-service analytics for 4 key stakeholder groups.</p> <p>Success Criteria:</p> <ul> <li>\u2705 100% revenue reconciliation with Finance audit trail</li> <li>\u2705 &lt;2 second dashboard load time for 95% of visuals</li> <li>\u2705 Zero critical data quality failures in production</li> <li>\u2705 3-page executive app deployed with RLS regional filtering</li> </ul> <p>Timeline: Phase 1-5 (Dec 2025 \u2013 Feb 2026) | improved decision velocity by 5x (Projected)</p>"},{"location":"00_business_requirements/#1-business-context","title":"1\ufe0f\u20e3 Business Context","text":""},{"location":"00_business_requirements/#11-domain-overview","title":"1.1 Domain Overview","text":"<p>Olist operates a multi-seller e-commerce marketplace in Brazil, connecting small merchants (\"Sellers\") to major marketplaces. The platform orchestrates a complex ecosystem of Orders, Payments, Logistics, and Reviews, acting as the connective tissue between decentralized sellers and centralized demand.</p>"},{"location":"00_business_requirements/#12-the-business-problem-the-trust-gap","title":"1.2 The Business Problem (The \"Trust Gap\")","text":"<p>As Olist scaled, its data ecosystem fragmented into siloed operational stores. Reporting became reactive, relying on manual CSV exports and fragile ad-hoc SQL scripts.</p> <ul> <li>Pain Point 1: Sales, Finance, and Ops teams report different revenue numbers for the same period.</li> <li>Pain Point 2: No visibility into \"Lost Revenue\" due to logistics failures or catalog errors.</li> <li>Pain Point 3: Regional managers lack sub-second access to performance data, relying on stale weekly PDFs.</li> </ul>"},{"location":"00_business_requirements/#13-strategic-vision","title":"1.3 Strategic Vision","text":"<p>To transition from \"Start-up\" to \"Scale-up,\" Olist must shift from gut-feel decision-making to precision analytics. This project establishes a Modern Data Stack (MDS)\u2014utilizing Snowflake, dbt, and Power BI\u2014to deliver a Single Source of Truth (SSOT).</p>"},{"location":"00_business_requirements/#2-stakeholders-user-personas","title":"2\ufe0f\u20e3 Stakeholders &amp; User Personas","text":"User Persona Role Focus Key Pain Point Decisions Enabled C-Level Executives Strategy &amp; Growth \"I don't know if we are profitable on a unit-economics basis.\" Allocate capital to high-growth categories; Pivot strategy based on YoY trends. Ops Managers Logistics &amp; SLA \"I find out about delivery bottlenecks 3 days too late.\" Re-route orders from failing hubs; Switch logistics partners in high-fail states. Sales Managers Seller Performance \"I can't identify which sellers are hurting our brand reputation.\" Offboard high-risk sellers; Create \"Gold Tier\" rewards for top performers. Finance Team Revenue Audit \"I spend 4 days a month reconciling spreadsheets.\" Close books faster with \"Verified Revenue\" vs. \"Revenue at Risk\" visibility."},{"location":"00_business_requirements/#3-objectives-success-criteria","title":"3\ufe0f\u20e3 Objectives &amp; Success Criteria","text":""},{"location":"00_business_requirements/#primary-objectives","title":"Primary Objectives","text":"<ol> <li>Metric Standardization: Enforce strict, code-based definitions for \"Realized Revenue\" and \"Delivery Delay\" to eliminate metric drift.</li> <li>Latency Reduction: Reduce \"Time-to-Insight\" from Weekly (Manual) to Daily (Automated T-1 Refresh).</li> <li>Self-Service: Empower non-technical managers to slice data by Region/Category without SQL requests.</li> </ol>"},{"location":"00_business_requirements/#success-metrics-definition-of-done","title":"Success Metrics (Definition of Done)","text":"<ul> <li>Trust: 100% numerical reconciliation between Finance \"Gold Numbers\" and Dashboard Revenue.</li> <li>\ud83d\udcf8 Validation: UAT Revenue Reconciliation</li> <li>Performance: Dashboard report pages load in &lt; 2 seconds for 95% of queries.</li> <li>\ud83d\udcf8 Validation: Performance Analyzer Results</li> <li>Data Quality: Zero critical failures (Duplicates, Null Primary Keys) allowed in the Production pipeline.</li> <li>\ud83d\udcf8 Validation: dbt Test Suite (100% Pass Rate)</li> </ul>"},{"location":"00_business_requirements/#4-key-business-questions-kbqs","title":"4\ufe0f\u20e3 Key Business Questions (KBQs)","text":"<p>The dashboard is designed to answer these specific strategic questions:</p> ID Business Question Analytics Type Value Add Q1 How are revenue and orders trending MoM/YoY? Descriptive Identifying growth stagnation early to adjust marketing spend. Q2 Which product categories drive the most margin? Descriptive Prioritizing inventory and seller onboarding efforts. Q3 Where is the demand concentrated geographically? Descriptive Optimizing logistics hub locations and shipping routes. Q4 How efficient is our delivery network? Diagnostic Pinpointing failing carrier routes (e.g., \"SP to RJ\"). Q5 Who are our \"Whale\" sellers vs. \"Churn\" risks? Descriptive Focused account management for top 1% of sellers. Q6 Are we retaining customers (Loyalty)? Descriptive Shifting strategy from \"Acquisition\" to \"Retention\" (LTV)."},{"location":"00_business_requirements/#5-kpi-definitions-logic","title":"5\ufe0f\u20e3 KPI Definitions &amp; Logic","text":"KPI Business Definition Technical Logic / Calculation Total Revenue Gross value of delivered items. <code>SUM(price)</code> where <code>order_status = 'delivered'</code> Total Orders Count of distinct valid orders. <code>COUNT(DISTINCT order_id)</code> where <code>order_status &lt;&gt; 'canceled'</code> Avg Order Value (AOV) Average spend per order. <code>Total Revenue</code> \u00f7 <code>Total Orders</code> Delivery Delay Rate % % of orders arriving late. <code>COUNT(late_orders)</code> \u00f7 <code>COUNT(delivered_orders)</code> where <code>delivered_at &gt; estimated_at</code> On-Time Delivery % % of orders arriving on/before promise. <code>1 - Delay Rate %</code> Revenue at Risk Value of orders with data quality issues. <code>SUM(price)</code> where <code>is_verified = False</code>"},{"location":"00_business_requirements/#6-business-rules-data-logic","title":"6\ufe0f\u20e3 Business Rules &amp; Data Logic","text":"<p>These rules govern how raw data is translated into business insights:</p>"},{"location":"00_business_requirements/#core-business-rules","title":"\ud83d\udccb Core Business Rules","text":"Rule Definition Enforcement Location Revenue Recognition Revenue is strictly recognized only when <code>order_status = 'delivered'</code>. Shipped or Invoiced orders are tracked for Operations but excluded from Financial totals. <code>stg_orders.sql</code> Efficiency Rule A delivery is flagged \"Late\" strictly if <code>order_delivered_customer_date &gt; order_estimated_delivery_date</code>. Weekends/Holidays are included (Customer View). <code>int_orders_enriched.sql</code> Identity Rule A \"Customer\" is defined by <code>customer_unique_id</code> (The Human), NOT <code>customer_id</code> (The Transaction). <code>dim_customers.sql</code> Verification Rule We apply a \"Trust, Don't Trash\" philosophy. Records with quality issues are Flagged (<code>is_verified = False</code>) rather than deleted. All STAGING layer models <p>\ud83d\udcf8 Implementation Evidence:</p> <ul> <li>Data Contracts in dbt - Business rules codified as tests</li> <li>Trust Indicators in Power BI - User-facing verification flags</li> </ul>"},{"location":"00_business_requirements/#7-data-scope-granularity","title":"7\ufe0f\u20e3 Data Scope &amp; Granularity","text":""},{"location":"00_business_requirements/#analytical-grain","title":"Analytical Grain","text":"<pre><code>\ud83d\udcca Fact Grain: One row per Order Line Item\n</code></pre> <p>Justification: Analysis requires slicing by Product Category and Seller Location. A grain of \"Order Header\" would obscure multi-category orders.</p>"},{"location":"00_business_requirements/#assumptions-limitations","title":"Assumptions &amp; Limitations","text":"Constraint Value Historical Range Sep 2016 \u2013 Oct 2018 (Dataset Limitation) Currency BRL (Brazilian Real) Timezone UTC (Pipeline) / UTC-3 (Reporting)"},{"location":"00_business_requirements/#8-non-functional-requirements-nfrs","title":"8\ufe0f\u20e3 Non-Functional Requirements (NFRs)","text":""},{"location":"00_business_requirements/#81-data-quality-trust","title":"8.1 Data Quality &amp; Trust","text":"<ul> <li>Constraint: The pipeline must halt if &gt;5% of daily volume fails validation.</li> <li>Visibility: All \"Raw\" vs. \"Verified\" data discrepancies must be visible in a dedicated \"Data Audit\" page.</li> </ul> <p>\ud83d\udcf8 Implementation Screenshots:</p> <ul> <li>Data Quality Audit Dashboard - Anomaly visibility</li> <li>dbt Test Results - Automated validation pipeline</li> </ul>"},{"location":"00_business_requirements/#82-security-access-rls","title":"8.2 Security &amp; Access (RLS)","text":"<ul> <li>Regional Restriction: Managers must only see data for their specific States (e.g., \"SP Manager\" sees only <code>customer_state = 'SP'</code>).</li> <li>Implementation: Dynamic RLS via Bridge Table (<code>User Email</code> \u2192 <code>Access Key</code> \u2192 <code>State Code</code>).</li> </ul> <p>\ud83d\udcf8 Implementation Screenshots:</p> <ul> <li>Snowflake RBAC Configuration - Role-based access control</li> <li>Power BI RLS Validation - Regional data filtering test</li> </ul>"},{"location":"00_business_requirements/#83-performance","title":"8.3 Performance","text":"<ul> <li>Refresh: Data must be refreshed daily by 05:00 AM local time.</li> <li>Interactivity: Visuals must render in &lt; 2 seconds.</li> </ul> <p>\ud83d\udcf8 Implementation Screenshots:</p> <ul> <li>Incremental Refresh Strategy - Optimized data refresh</li> <li>Query Folding Evidence - Native query pushdown to Snowflake</li> </ul>"},{"location":"00_business_requirements/#out-of-scope-phase-1","title":"\ud83d\udd1f Out of Scope (Phase 1)","text":"<p>| Feature                    | Status          | | :------------------------- | :-------------- | --- | | Sentiment Analysis     | \u23f8\ufe0f Deferred     | | Predictive Forecasting | \u23f8\ufe0f Deferred     | | Real-Time Streaming    | \u274c Not Required |     |</p>"},{"location":"00_business_requirements/#11-deliverables-checklist","title":"1\ufe0f\u20e31\ufe0f\u20e3 Deliverables Checklist","text":""},{"location":"00_business_requirements/#phase-1-deliverables","title":"\u2705 Phase 1 Deliverables","text":"<ul> <li>[x] Semantic Model: Certified Power BI Dataset (<code>.pbip</code>) with Star Schema architecture.</li> <li>\ud83d\udcf8 Semantic Model Diagram</li> <li>\ud83d\udcf8 Data Lineage View</li> <li>[x] Executive App: 3-Page Dashboard (Overview, Logistics Deep Dive, Data Audit).</li> <li>\ud83d\udcf8 Executive Overview</li> <li>\ud83d\udcf8 Supply Chain Analysis</li> <li>\ud83d\udcf8 Data Quality Audit</li> <li>[x] Documentation:</li> <li>Architecture Diagram</li> <li>Data Dictionary</li> <li>\ud83d\udcf8 dbt Documentation Site</li> </ul>"},{"location":"01_architecture/","title":"Architecture","text":""},{"location":"01_architecture/#system-architecture-overview","title":"\ud83c\udfd7\ufe0f System Architecture Overview","text":"<p>Portfolio Scenario \u2014 Architecture</p> <p>\u26a0\ufe0f Portfolio Scenario: This architecture describes a simulated Digital Transformation implementation for the Olist public dataset. It documents design decisions and controls as production-style patterns for portfolio demonstration.</p> <p>Scope</p> <p>This file defines the system architecture and key engineering decisions.</p> <p>Single Source of Truth (SSOT) Rule</p> <p>Definitions live once, then referenced:</p> <pre><code>- Business definitions and KPI rules: [00_business_requirements.md](00_business_requirements.md)\n- Column-level semantics: [02_data_dictionary.md](02_data_dictionary.md)\n- Data quality framework and controls: [03_data_quality.md](03_data_quality.md)\n- Semantic model design and DAX standards: [04_semantic_model.md](04_semantic_model.md)\n- Engineering standards and DataOps controls: [06_engineering_standards.md](06_engineering_standards.md)\n</code></pre>"},{"location":"01_architecture/#1-architecture-at-a-glance","title":"1. Architecture at a Glance","text":"<p>System Pattern: Modern Data Stack (Azure Blob \u2192 Snowflake \u2192 dbt \u2192 Power BI).</p> <p>Objective: Provide a trustworthy, low-latency analytics platform with reproducible transformations, explicit quality gates, and governed semantic consumption.</p> <p></p>"},{"location":"01_architecture/#evidence","title":"Evidence","text":""},{"location":"01_architecture/#system-lineage-dag","title":"System Lineage (DAG)","text":"<ul> <li>Snowflake schema separation: database.png</li> <li>Semantic model implementation: semantic_model.png</li> </ul>"},{"location":"01_architecture/#2-decision-log-senior-format","title":"2. Decision Log (Senior Format)","text":"Decision Rationale Trade-off Evidence Warehouse: Snowflake Separated compute/storage, zero-copy cloning, strong dbt adapter maturity Cost discipline required via warehouse sizing and auto-suspend warehouse.png Modeling Pattern: Kimball Star Schema Faster BI queries, clear fact grain, reusable conformed dimensions More modeling upfront than wide flat-table approach marts_data_model.png Transform Engine: dbt Core SQL-first workflows, test-native framework, lineage auto-generation Requires strict naming/testing discipline test_passed_suite.png Consumption Mode: Power BI Import Sub-2s dashboard interactions, predictable user experience Scheduled freshness vs real-time DirectQuery performance_analyzer_excutive_page.png Quality Policy: Blocking CI gates Prevents bad models/metrics from reaching reports Slower merges when tests fail github_pr_checks_pass.png"},{"location":"01_architecture/#3-end-to-end-flow-concise","title":"3. End-to-End Flow (Concise)","text":"<p>Data Flow: Azure Blob \u2192 Snowflake RAW \u2192 dbt STAGING/INTERMEDIATE/MARTS \u2192 Power BI Semantic Model.</p>"},{"location":"01_architecture/#flow-controls","title":"Flow Controls","text":"<ul> <li>Ingestion control: idempotent load pattern into RAW (<code>FORCE = FALSE</code> policy in ingestion scripts).</li> <li>Transformation control: model dependencies enforced by dbt <code>ref()</code> lineage.</li> <li>Quality control: 559 blocking tests in CI (<code>dbt build --target dev/prod</code>).</li> <li>Consumption control: semantic model connects to MARTS only (no RAW/STAGING exposure).</li> </ul> <p>Quality Gate</p> <p>559 automated tests execute as blocking checks in CI. Failed tests block promotion.</p>"},{"location":"01_architecture/#4-layer-responsibilities-no-repetition","title":"4. Layer Responsibilities (No Repetition)","text":"<p>For detailed naming, columns, and business definitions, use linked SSOT docs. This section only states architectural ownership and contracts.</p>"},{"location":"01_architecture/#41-raw-layer","title":"4.1 RAW Layer","text":"<ul> <li>Materialization: Transient tables</li> <li>Contract: Immutable landing zone + audit columns</li> <li>Owner: Loader role</li> <li>Purpose: Preserve source fidelity for replay/audit</li> </ul> <p>Evidence: row_count.png</p>"},{"location":"01_architecture/#42-staging-layer","title":"4.2 STAGING Layer","text":"<ul> <li>Materialization: Views</li> <li>Contract: Type casting, standardization, no business joins</li> <li>Owner: Analytics role</li> <li>Purpose: Stable technical interface to source data</li> </ul> <p>Reference details: 02_data_dictionary.md</p>"},{"location":"01_architecture/#43-intermediate-layer","title":"4.3 INTERMEDIATE Layer","text":"<ul> <li>Materialization: Ephemeral models</li> <li>Contract: Business transformations and reusable joins</li> <li>Owner: Analytics role</li> <li>Purpose: Reusable business logic before mart serving</li> </ul> <p>Reference details: 06_engineering_standards.md</p>"},{"location":"01_architecture/#44-marts-layer","title":"4.4 MARTS Layer","text":"<ul> <li>Materialization: Tables + incremental facts</li> <li>Contract: Star schema optimized for BI</li> <li>Owner: Analytics role (write), reporter role (read)</li> <li>Purpose: Trusted analytical interface</li> </ul> <p>Evidence: semantic_model.png</p>"},{"location":"01_architecture/#5-problem-fix-impact-scan-friendly","title":"5. Problem \u2192 Fix \u2192 Impact (Scan-Friendly)","text":""},{"location":"01_architecture/#51-dashboard-latency","title":"5.1 Dashboard Latency","text":"<ul> <li>Problem: Report interactions exceeded acceptable UX thresholds.</li> <li>Fix: Import mode + star schema + incremental refresh policy.</li> <li>Impact: Dashboard interactions reduced to sub-2s target range.</li> <li>Evidence: incremental_refresh.png, performance_analyzer_excutive_page.png</li> </ul>"},{"location":"01_architecture/#52-metric-inconsistency-across-stakeholders","title":"5.2 Metric Inconsistency Across Stakeholders","text":"<ul> <li>Problem: Different report logic produced inconsistent KPI values.</li> <li>Fix: Business logic centralized in dbt marts and semantic measures.</li> <li>Impact: Revenue and core KPI definitions aligned through one governed model.</li> <li>Reference: 00_business_requirements.md, 04_semantic_model.md</li> </ul>"},{"location":"01_architecture/#53-risk-of-broken-production-changes","title":"5.3 Risk of Broken Production Changes","text":"<ul> <li>Problem: Unvalidated model changes can break dashboards.</li> <li>Fix: PR approvals + CI test gates + linting + deployment workflow.</li> <li>Impact: Only validated changes are promoted.</li> <li>Evidence: ci_dbt_build_pass.png, github_pr_checks_pass.png</li> </ul>"},{"location":"01_architecture/#6-security-and-access-boundaries","title":"6. Security and Access Boundaries","text":""},{"location":"01_architecture/#61-warehouse-security","title":"6.1 Warehouse Security","text":"<ul> <li>Role hierarchy applies least-privilege boundaries between loading, transformation, and reporting responsibilities.</li> <li>Production reporting role is read-only on marts.</li> </ul> <p>Evidence: RBAC.png</p>"},{"location":"01_architecture/#62-semantic-security","title":"6.2 Semantic Security","text":"<ul> <li>RLS enforced in semantic layer using mapping table policy.</li> <li>Regional access control validated through UAT scenarios.</li> </ul> <p>Evidence: uat_rls_validation.png</p>"},{"location":"01_architecture/#7-cost-and-performance-guardrails","title":"7. Cost and Performance Guardrails","text":"<ul> <li>Warehouse sizing: X-Small defaults with aggressive auto-suspend.</li> <li>Storage strategy: RAW transient + STAGING views to reduce overhead.</li> <li>Build strategy: Incremental facts for shorter refresh windows.</li> <li>Monitoring: Query/runtime checks and CI results reviewed per release.</li> </ul> <p>Reference details: 05_performance_optimization.md</p>"},{"location":"01_architecture/#9-evidence-index","title":"9. Evidence Index","text":""},{"location":"01_architecture/#infrastructure","title":"Infrastructure","text":"<ul> <li>Azure structure: container_structure.png</li> <li>Snowflake schemas: database.png</li> <li>Snowflake warehouses: warehouse.png</li> </ul>"},{"location":"01_architecture/#transformation-and-quality","title":"Transformation and Quality","text":"<ul> <li>dbt DAG: lineage_dag.png</li> <li>dbt tests: test_passed_suite.png</li> <li>dbt contracts: data_contracts.png</li> </ul>"},{"location":"01_architecture/#bi-and-governance","title":"BI and Governance","text":"<ul> <li>Semantic model: semantic_model.png</li> <li>Incremental refresh: incremental_refresh.png</li> <li>RLS validation: uat_rls_validation.png</li> </ul>"},{"location":"01_architecture/#dataops","title":"DataOps","text":"<ul> <li>CI pass: ci_dbt_build_pass.png</li> <li>PR quality gates: github_pr_checks_pass.png</li> <li>Roadmap tracking: project_milestones_roadmap.png</li> </ul>"},{"location":"02_data_dictionary/","title":"Data Dict","text":""},{"location":"02_data_dictionary/#data-dictionary-dbt-marts-layer","title":"\ud83d\udcda Data Dictionary \u2014 dbt MARTS Layer","text":"<p>Portfolio Scenario \u2014 MARTS Dictionary</p> <p>This dictionary documents the dbt MARTS layer for a simulated Digital Transformation portfolio implementation. Definitions are aligned to current dbt model SQL/YAML and intended for governance, handoff, and auditability.</p>"},{"location":"02_data_dictionary/#1-purpose-scope","title":"1. Purpose &amp; Scope","text":"<p>This document is the canonical reference for MARTS-layer structure and semantics.</p> <p>It defines:</p> <ul> <li>Fact and dimension responsibilities</li> <li>Grain for each MARTS model</li> <li>Business rules embedded in SQL transformations</li> <li>Source-to-target lineage from INT/STG/SEED to MARTS</li> <li>Relationship and key strategy for BI consumption</li> </ul> <p>Scope includes these dbt models:</p> <ul> <li><code>marts.sales.fct_order_items</code></li> <li><code>marts.core.dim_customers</code></li> <li><code>marts.core.dim_products</code></li> <li><code>marts.core.dim_sellers</code></li> <li><code>marts.core.dim_date</code></li> <li><code>marts.core.dim_rls_bridge</code></li> <li><code>security.dim_security_rls</code></li> <li><code>marts.meta.meta_project_status</code></li> </ul>"},{"location":"02_data_dictionary/#2-modeling-philosophy-kimball-approach","title":"2. Modeling Philosophy (Kimball Approach)","text":"<p>The MARTS layer follows Kimball dimensional modeling:</p> <ul> <li>One central transactional fact (<code>fct_order_items</code>)</li> <li>Conformed dimensions reused across analyses</li> <li>Explicit surrogate key joins for BI consistency</li> <li>\u201cFlag, don\u2019t filter\u201d for data quality transparency</li> </ul> <p>Design decisions applied in this project:</p> <ul> <li>Keep all order statuses in fact table; metric filtering is handled in semantic/DAX layer.</li> <li>Preserve diagnostic flags (<code>is_verified</code>, <code>quality_issue_reason</code>) instead of removing rows.</li> <li>Keep marts SQL simple (heavy transformations done upstream in INTERMEDIATE).</li> </ul> <p>Visual Reference: dbt Lineage (RAW \u2192 STAGING \u2192 INTERMEDIATE \u2192 MARTS)</p> <p></p> <p>Figure 1: Complete data transformation lineage showing the star schema pattern with <code>fct_order_items</code> as the central fact table and conformed dimensions.</p>"},{"location":"02_data_dictionary/#3-fact-tables","title":"3. Fact Tables","text":""},{"location":"02_data_dictionary/#31-fct_order_items","title":"3.1 <code>fct_order_items</code>","text":"<p>Purpose: Central fact for revenue, order, delivery, retention, and quality reporting.</p> <p>Model config (dbt):</p> <ul> <li>Materialization: <code>incremental</code></li> <li>Unique key: <code>order_item_sk</code></li> <li>Schema: <code>marts</code></li> <li>On-schema-change: <code>append_new_columns</code></li> </ul> <p>Business notes:</p> <ul> <li>Includes delivered + non-delivered statuses for full funnel analysis.</li> <li>Supports recognized revenue and lost revenue patterns downstream.</li> </ul> <p>See also: Section 5 (Table Grain Definitions) for explicit grain specification and Section 8 (Source-to-Target Mapping) for upstream lineage.</p> <p>Visual Reference: Incremental Materialization Strategy</p> <p></p> <p>Figure 2: Incremental model configuration in dbt showing <code>unique_key</code> strategy and on-schema-change behavior for the fact table.</p>"},{"location":"02_data_dictionary/#4-dimension-tables","title":"4. Dimension Tables","text":"<p>See also: Section 10 (Surrogate Keys &amp; Relationships) for relationship mappings to the fact table.</p>"},{"location":"02_data_dictionary/#41-dim_customers","title":"4.1 <code>dim_customers</code>","text":"<ul> <li>Purpose: customer master for segmentation and retention</li> <li>Key fields: <code>customer_sk</code>, <code>customer_unique_id</code>, location attributes</li> </ul>"},{"location":"02_data_dictionary/#42-dim_products","title":"4.2 <code>dim_products</code>","text":"<ul> <li>Purpose: product catalog with translated category and quality signals</li> <li>Key fields: <code>product_sk</code>, <code>product_id</code>, <code>product_category</code>, quality attributes</li> </ul>"},{"location":"02_data_dictionary/#43-dim_sellers","title":"4.3 <code>dim_sellers</code>","text":"<ul> <li>Purpose: seller master and geography for performance + security propagation</li> <li>Key fields: <code>seller_sk</code>, <code>seller_id</code>, <code>seller_state_code</code>, <code>seller_city</code></li> </ul>"},{"location":"02_data_dictionary/#44-dim_date","title":"4.4 <code>dim_date</code>","text":"<ul> <li>Purpose: conformed calendar for time-series analysis</li> <li>Key fields: <code>date_day</code>, year/quarter/month/day attributes, weekend flag</li> </ul>"},{"location":"02_data_dictionary/#45-dim_security_rls","title":"4.5 <code>dim_security_rls</code>","text":"<ul> <li>Purpose: user-to-access mapping for row-level security entry point</li> <li>Key fields: <code>user_email</code>, <code>access_key</code>, <code>access_level</code></li> </ul>"},{"location":"02_data_dictionary/#46-dim_rls_bridge","title":"4.6 <code>dim_rls_bridge</code>","text":"<ul> <li>Purpose: translates <code>access_key</code> to <code>seller_state_code</code> for filter propagation</li> <li>Key fields: <code>access_key</code>, <code>seller_state_code</code></li> </ul>"},{"location":"02_data_dictionary/#47-meta_project_status","title":"4.7 <code>meta_project_status</code>","text":"<ul> <li>Purpose: pipeline and business data freshness metadata</li> <li>Key fields: <code>pipeline_last_run_at</code>, <code>data_valid_through</code></li> </ul>"},{"location":"02_data_dictionary/#5-table-grain-definitions","title":"5. Table Grain Definitions","text":"Model Grain <code>fct_order_items</code> One row per order item (line-level transaction) <code>dim_customers</code> One row per unique customer (<code>customer_sk</code>) <code>dim_products</code> One row per unique product (<code>product_id</code>) <code>dim_sellers</code> One row per unique seller (<code>seller_id</code>) <code>dim_date</code> One row per calendar day <code>dim_security_rls</code> One row per (<code>user_email</code>, <code>access_key</code>) pair <code>dim_rls_bridge</code> One row per (<code>access_key</code>, <code>seller_state_code</code>) pair <code>meta_project_status</code> Singleton (one row)"},{"location":"02_data_dictionary/#6-column-level-definitions","title":"6. Column-Level Definitions","text":""},{"location":"02_data_dictionary/#61-fct_order_items-selected-columns","title":"6.1 <code>fct_order_items</code> (selected columns)","text":"Column Type Definition Rule <code>order_item_sk</code> <code>varchar</code> Surrogate PK for line item Unique, not null <code>customer_sk</code> <code>varchar</code> FK to customer dimension Must map to <code>dim_customers</code> <code>product_sk</code> <code>varchar</code> FK to product dimension Must map to <code>dim_products</code> <code>seller_sk</code> <code>varchar</code> FK to seller dimension Must map to <code>dim_sellers</code> <code>order_date_dt</code> <code>date</code> Order date key Must map to <code>dim_date.date_day</code> <code>order_id</code> <code>varchar</code> Natural order key Used for distinct-order metrics <code>order_status</code> <code>varchar</code> Standardized order status (InitCap) Includes delivered/canceled/etc <code>price_brl</code> <code>numeric(10,2)</code> Line-item price in BRL Must be <code>&gt;= 0</code> (warn threshold) <code>freight_value_brl</code> <code>numeric(10,2)</code> Freight value in BRL Must be <code>&gt;= 0</code> (warn threshold) <code>order_sequence_number</code> <code>integer</code> Customer order sequence Must be <code>&gt;= 1</code> <code>delivery_time_days</code> <code>integer</code> Delivery duration days Nullable for non-delivered orders <code>is_delayed</code> <code>integer</code> Delivery delay flag Accepted values: <code>0/1</code> <code>is_verified</code> <code>integer</code> Master quality flag Accepted values: <code>0/1</code> <code>quality_issue_reason</code> <code>varchar</code> Quality diagnostic reason Populated when quality checks fail"},{"location":"02_data_dictionary/#62-core-dimensions-selected-columns","title":"6.2 Core dimensions (selected columns)","text":"Table Column Definition <code>dim_customers</code> <code>customer_sk</code> Surrogate customer key <code>dim_customers</code> <code>customer_state_code</code> 2-letter BR state code <code>dim_products</code> <code>product_category</code> English category name <code>dim_products</code> <code>product_category_original</code> Portuguese source category <code>dim_sellers</code> <code>seller_state_code</code> RLS target geography code <code>dim_date</code> <code>year_month_number</code> Numeric sort key (<code>YYYYMM</code>) <code>dim_date</code> <code>is_weekend</code> Weekend indicator (1/0)"},{"location":"02_data_dictionary/#7-business-rules-embedded-in-transformations","title":"7. Business Rules Embedded in Transformations","text":"<p>Rules implemented in MARTS SQL contracts:</p> <ul> <li><code>fct_order_items</code> keeps all order statuses; no hard delivered-only filter in marts.</li> <li><code>order_status</code> is normalized to title case (<code>initcap</code>).</li> <li>Data-quality attributes are preserved, not dropped.</li> <li>Incremental loads refresh by latest <code>order_date_dt</code> boundary.</li> </ul> <p>Rules enforced through tests/contracts (YAML):</p> <ul> <li>Key uniqueness and not-null constraints</li> <li>FK relationship checks to dimensions</li> <li>Accepted value checks (statuses, binary flags, state codes)</li> <li>Numeric range checks for financial and operational metrics</li> </ul> <p>Visual Reference: dbt Test Suite Results</p> <p></p> <p>Figure 3: Comprehensive test coverage with 100% pass rate across generic and singular tests for data quality validation.</p>"},{"location":"02_data_dictionary/#8-source-to-target-mapping","title":"8. Source-to-Target Mapping","text":"<p>Reference: See Section 2 (Modeling Philosophy) for transformation layer responsibilities.</p> MARTS Model Upstream Source Mapping Notes <code>fct_order_items</code> <code>int_sales__order_items_joined</code> Pass-through of precomputed metrics and quality flags <code>dim_customers</code> <code>int_customers__prep</code> Uses deduplicated customer identity <code>dim_products</code> <code>int_products__enriched</code> Uses translated categories + quality fields <code>dim_sellers</code> <code>stg_olist__sellers</code> Standardized seller geography <code>dim_date</code> dbt-generated date spine Generated <code>2016-01-01</code> to <code>2018-12-31</code> <code>dim_security_rls</code> <code>seed.security_rls_mapping</code> User access mapping seed <code>dim_rls_bridge</code> <code>seed.security_rls_mapping</code> Distinct access key bridge <code>meta_project_status</code> <code>fct_order_items</code> + runtime clock Pipeline and business \u201ctwo clocks\u201d <p>Visual Reference: dbt Documentation Site</p> <p></p>"},{"location":"02_data_dictionary/#figure-4-auto-generated-dbt-documentation-site-showing-complete-model-catalog-lineage-visualization-and-column-level-descriptions-for-all-marts-models","title":"Figure 4: Auto-generated dbt documentation site showing complete model catalog, lineage visualization, and column-level descriptions for all MARTS models.","text":""},{"location":"02_data_dictionary/#9-data-types-naming-standards","title":"9. Data Types &amp; Naming Standards","text":"<p>Naming standards:</p> <ul> <li>Fact tables: prefix <code>fct_</code></li> <li>Dimensions: prefix <code>dim_</code></li> <li>Metadata/ops: prefix <code>meta_</code></li> <li>Surrogate keys: suffix <code>_sk</code></li> <li>State code attributes: suffix <code>_state_code</code></li> <li>Timestamps: suffix <code>_at</code></li> </ul> <p>Data type standards:</p> <ul> <li>Keys: <code>varchar</code></li> <li>Money: <code>numeric(10,2)</code></li> <li>Flags: integer <code>0/1</code> in marts (cast to boolean in semantic layer where needed)</li> <li>Dates: <code>date</code></li> <li>Datetimes/audit: <code>timestamp_ltz</code> (project uses <code>timestamp_lptz</code> in <code>dim_security_rls</code> implementation)</li> </ul>"},{"location":"02_data_dictionary/#10-surrogate-keys-relationships","title":"10. Surrogate Keys &amp; Relationships","text":"<p>Primary surrogate keys:</p> <ul> <li><code>fct_order_items.order_item_sk</code></li> <li><code>dim_customers.customer_sk</code></li> <li><code>dim_products.product_sk</code></li> <li><code>dim_sellers.seller_sk</code></li> <li><code>dim_date.date_day</code> (date PK)</li> </ul> <p>Core star-schema relationships:</p> <ul> <li><code>fct_order_items.customer_sk</code> \u2192 <code>dim_customers.customer_sk</code></li> <li><code>fct_order_items.product_sk</code> \u2192 <code>dim_products.product_sk</code></li> <li><code>fct_order_items.seller_sk</code> \u2192 <code>dim_sellers.seller_sk</code></li> <li><code>fct_order_items.order_date_dt</code> \u2192 <code>dim_date.date_day</code></li> </ul> <p>RLS relationship pattern:</p> <ul> <li><code>dim_security_rls.access_key</code> \u2192 <code>dim_rls_bridge.access_key</code></li> <li><code>dim_rls_bridge.seller_state_code</code> \u2192 <code>dim_sellers.seller_state_code</code></li> </ul>"},{"location":"02_data_dictionary/#11-audit-metadata-columns","title":"11. Audit &amp; Metadata Columns","text":"<p>Standard audit pattern:</p> <ul> <li>Most marts models include <code>dbt_updated_at</code> as load/process timestamp.</li> </ul> <p>Operational metadata table:</p> <ul> <li><code>meta_project_status.pipeline_last_run_at</code>: pipeline execution timestamp.</li> <li><code>meta_project_status.data_valid_through</code>: latest business date in fact (<code>max(order_date_dt)</code>).</li> </ul> <p>Purpose:</p> <ul> <li>Freshness monitoring</li> <li>Dashboard footer/system status</li> <li>Audit and incident triage support</li> </ul>"},{"location":"02_data_dictionary/#12-change-management-schema-evolution","title":"12. Change Management &amp; Schema Evolution","text":"<p>See also: Section 7 (Business Rules) for contract enforcement through tests.</p> <p>Current controls:</p> <ul> <li>dbt model contracts (<code>contract.enforced: true</code>) in marts schemas</li> <li>Explicit column selection in SQL (no uncontrolled <code>SELECT *</code> in marts outputs)</li> <li>Incremental strategy with stable unique key for facts</li> <li>Pull-request workflow and versioned SQL/YAML assets</li> </ul> <p>Schema evolution policy:</p> <ul> <li>Additive column changes are preferred.</li> <li>Breaking changes require model + YAML updates together.</li> <li>Downstream semantic model must validate renamed/removed fields before release.</li> </ul> <p>Visual Reference: dbt Model Contracts</p> <p></p> <p>Figure 5: Schema contracts enforced at MARTS layer ensuring column-level type safety and preventing breaking changes from upstream models.</p>"},{"location":"02_data_dictionary/#13-data-ownership-stewardship","title":"13. Data Ownership &amp; Stewardship","text":"Domain Primary Owner Stewardship Responsibility Snowflake MARTS Analytics Engineering Model design, contracts, performance Security mappings DataOps / Platform Admin Seed maintenance, access governance Semantic consumption BI / Analytics Developer Measure layer, report behavior, RLS role wiring KPI definitions Finance + Operations + Analytics Business-rule signoff and change control"},{"location":"02_data_dictionary/#14-limitations-assumptions","title":"14. Limitations &amp; Assumptions","text":"<p>Current limitations:</p> <ul> <li>Date mart range is fixed to dataset window (<code>2016-01-01</code> to <code>2018-12-31</code>).</li> <li><code>fct_order_items</code> uses order date as date key; delivery-date role-playing is a semantic-layer extension.</li> <li>Some performance/quality values are operationally monitored outside this dictionary.</li> </ul> <p>Assumptions:</p> <ul> <li>Upstream INT models remain the source of complex business logic.</li> <li>Seed <code>security_rls_mapping</code> is maintained as authoritative mapping input.</li> <li>BI layer applies final KPI filters (for example delivered-only revenue) where business requires.</li> </ul>"},{"location":"02_data_dictionary/#15-semantic-model-integration-added","title":"15. Semantic Model Integration (Added)","text":"<p>Reference: Section 10 (Surrogate Keys &amp; Relationships) defines the star schema relationships that Power BI implements.</p> <p>Why this section exists:</p> <ul> <li>MARTS contracts are only useful if semantic model mappings stay aligned.</li> </ul> <p>Alignment checkpoints:</p> <ul> <li><code>marts.fct_order_items</code> maps to semantic table <code>Sales</code>.</li> <li>Surrogate relationships remain 1:* from dimensions to fact.</li> <li>Quality flags (<code>is_verified</code>, <code>quality_issue_reason</code>) are exposed for verified vs at-risk measures.</li> <li>Security chain (<code>dim_security_rls</code> + <code>dim_rls_bridge</code> + <code>dim_sellers</code>) supports dynamic RLS in Power BI.</li> </ul> <p>Release checklist before publish:</p> <ol> <li><code>dbt build --select marts</code> passes.</li> <li>Contract/test failures are zero or accepted with documented exceptions.</li> <li>Semantic model refresh validates all mapped columns.</li> <li>KPI regression checks pass for core measures (<code>Total Revenue</code>, <code>Total Orders</code>, <code>AOV</code>, quality metrics).</li> </ol> <p>Visual Reference: MARTS-to-Semantic Model Relationships</p> <p></p> <p>Figure 6: Star schema relationship graph in Power BI showing one-to-many relationships from dimensions to the central <code>Sales</code> fact table (mapped from <code>fct_order_items</code>).</p> <p>Visual Reference: Power BI Semantic Model Structure</p> <p></p> <p>Figure 7: Complete semantic model structure in Power BI showing all imported MARTS tables, calculated measures, and field hierarchies ready for dashboard consumption.</p>"},{"location":"03_data_quality/","title":"Data Quality","text":""},{"location":"03_data_quality/#data-quality-testing-strategy","title":"Data Quality &amp; Testing Strategy","text":"<p>Portfolio Scenario \u2014 Data Quality</p> <p>\u26a0\ufe0f Portfolio Scenario: This document outlines the requirements for a simulated Digital Transformation project at Olist. It addresses real data quality issues found in the public dataset, treating them as live business risks.</p> <p>\ud83d\udcd8 SSOT References</p> <ul> <li>Architecture context: 01_architecture.md (layer responsibilities, data flow)</li> <li>Security controls: Section 6 of architecture doc (RBAC, RLS details)</li> <li>Performance optimization: 05_performance_optimization.md (speed = trust analysis)</li> <li>Business rules: 00_business_requirements.md (KPI definitions)</li> </ul>"},{"location":"03_data_quality/#1-quality-framework-at-a-glance","title":"1. Quality Framework at a Glance","text":"<p>Strategy: Flag anomalies, preserve 100% of data, expose dual metrics.</p> <p>Evidence: Screenshot Index (15 screenshots showing test results, CI enforcement, reconciliation)</p> Layer Test Count Focus Area Materialization RAW 85 source tests Freshness, row counts Transient tables STAGING 456 generic PK/FK integrity, enums Views INTERMEDIATE 18 singular Business rules, flags Ephemeral/tables MARTS 100% FK coverage Grain enforcement Tables/incremental Power BI Schema contracts Verified metrics Semantic model <p>Quality Flow:</p> <pre><code>Azure Blob \u2192 RAW (Freshness Check) \u2192 STAGING (PK/FK Tests) \u2192 INTERMEDIATE (Quality Flags) \u2192 MARTS (Contract Validation) \u2192 Power BI (Verified Measures)\n         \u2193              \u2193                      \u2193                         \u2193                        \u2193                          \u2193\n    85 source      456 generic           18 singular              Grain checks            Schema drift           Dual metrics\n     tests          tests                 tests                   enforcement             protection              exposed\n</code></pre>"},{"location":"03_data_quality/#2-decision-log","title":"2. Decision Log","text":"Decision Rationale Trade-off Evidence Flag vs. Delete Finance requires 100% reconciliation with ERP Slightly more complex DAX (Total vs. Verified) Revenue reconciliation 559 Automated Tests Zero-trust validation at every layer 5-minute CI runtime (acceptable for quality gate) CI pass screenshot dbt Singular Tests Generic tests can't validate cross-column business rules Maintenance overhead (18 custom SQL tests) Business rule tests Schema Contracts Fail-fast on breaking changes (not silent errors) Requires explicit type definitions in YAML Contract enforcement Dual Metric Strategy Stakeholders need both \"Total\" (audit) and \"Verified\" (exec) Dashboard users must understand quality context Trust tooltip UX"},{"location":"03_data_quality/#3-test-coverage-matrix","title":"3. Test Coverage Matrix","text":""},{"location":"03_data_quality/#31-test-pyramid","title":"3.1 Test Pyramid","text":"<pre><code>         \u25b2\n        \u2571 \u2572        18 Singular Tests (10% of total)\n       \u2571   \u2572       \u2022 No future order dates\n      \u2571     \u2572      \u2022 Timestamp sequence validation\n     \u2571\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2572     \u2022 Negative price checks\n    \u2571         \u2572\n   \u2571  456 Generic \u2572   Generic Tests (82% of total)\n  \u2571   dbt Tests   \u2571   \u2022 unique, not_null (100% PK coverage)\n \u2571   (Unit Tests) \u2572   \u2022 relationships (100% FK coverage)\n\u2571\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2572   \u2022 accepted_values (enums, states)\n                   \u2572\n               85 Source Tests (15% of total)\n               \u2022 Freshness &lt; 14 days\n               \u2022 Row count validation\n               \u2705 559 total tests\n</code></pre>"},{"location":"03_data_quality/#32-critical-business-rules","title":"3.2 Critical Business Rules","text":"Test Name Severity Rule Impact <code>assert_no_future_order_dates</code> ERROR <code>order_date &lt;= CURRENT_DATE</code> Prevents timeline corruption <code>assert_order_timestamps_logical_sequence</code> WARN Ordered \u2192 Approved \u2192 Shipped \u2192 Delivered Detects data quality issues <code>assert_no_negative_prices_or_freight</code> ERROR <code>price &gt;= 0 AND freight &gt;= 0</code> Protects revenue calculations <code>assert_delivered_orders_have_delivery_date</code> ERROR <code>status='delivered' \u2192 date NOT NULL</code> Ensures SLA accuracy"},{"location":"03_data_quality/#33-coverage-summary","title":"3.3 Coverage Summary","text":"Coverage Type Target Actual Status Primary Keys 100% 29/29 models \u2705 Foreign Keys 100% 17/17 relations \u2705 Source Freshness 100% 8/8 RAW tables \u2705 State Enum 100% 27 BR states \u2705 Test Pass Rate 100% 559/559 tests \u2705"},{"location":"03_data_quality/#4-problem-fix-impact","title":"4. Problem \u2192 Fix \u2192 Impact","text":""},{"location":"03_data_quality/#problem-1-finance-cant-reconcile-revenue","title":"Problem 1: Finance Can't Reconcile Revenue","text":"<p>Problem:</p> <ul> <li>Deleting anomalous orders breaks total reconciliation with source ERP</li> <li>3 departments report different \"Total Revenue\" numbers</li> <li>Audit compliance at risk</li> </ul> <p>Fix:</p> <ul> <li>Strategy: \"Flag, Don't Delete\"</li> <li>Implementation: Add <code>is_verified</code> column in INTERMEDIATE layer</li> <li>Expose dual metrics in Power BI: <code>[Total Revenue]</code> vs. <code>[Verified Revenue]</code></li> </ul> <p>Impact:</p> <pre><code>Total Revenue:     R$ 13,591,643  (100% - matches Finance ERP)\nVerified Revenue:  R$ 13,564,851  (99.8% - executive reporting)\nRevenue at Risk:   R$ 26,792      (0.2% - flagged for investigation)\n</code></pre> <ul> <li>Result: Finance achieves 100% reconciliation, Executives use 99.8% verified subset</li> <li>Evidence: UAT Revenue Reconciliation Screenshot</li> </ul>"},{"location":"03_data_quality/#problem-2-schema-changes-break-dashboards-silently","title":"Problem 2: Schema Changes Break Dashboards Silently","text":"<p>Problem:</p> <ul> <li>Power BI refreshes succeeded despite column renames in dbt</li> <li>Visuals showed blank data, no error alerts</li> <li>2-day delayed detection by business users</li> </ul> <p>Fix:</p> <ul> <li>dbt: <code>contract: enforced: true</code> in MARTS models (compile-time validation)</li> <li>Power Query: <code>Table.SelectColumns()</code> explicit selection (fail-fast on missing columns)</li> </ul> <p>Impact:</p> <ul> <li>Before: Silent failures \u2192 2-day detection lag</li> <li>After: Immediate CI failure \u2192 &lt; 5 minutes detection</li> <li>Evidence: dbt Contract Enforcement Screenshot, Power BI Schema Error</li> </ul>"},{"location":"03_data_quality/#problem-3-timestamp-violations-corrupt-sla-metrics","title":"Problem 3: Timestamp Violations Corrupt SLA Metrics","text":"<p>Problem:</p> <ul> <li>127 orders have <code>delivered_at &lt; ordered_at</code> (impossible timeline)</li> <li>SLA \"Days to Deliver\" metric shows negative values</li> <li>Operations team loses trust in dashboard accuracy</li> </ul> <p>Fix:</p> <ul> <li>Singular Test: <code>assert_order_timestamps_logical_sequence.sql</code></li> <li>Quality Flag: <code>has_timestamp_violation</code> column</li> <li>DAX Filter: <code>[SLA Metrics]</code> only use <code>is_verified = TRUE</code> orders</li> </ul> <p>Impact:</p> <ul> <li>Before: Negative SLA values \u2192 Dashboard credibility failure</li> <li>After: 99.8% clean SLA metrics \u2192 Operations trust restored</li> <li>Evidence: Timestamp Validation Test Results</li> </ul>"},{"location":"03_data_quality/#5-quality-flag-logic","title":"5. Quality Flag Logic","text":"<p>Implementation Layer: <code>int_orders_enriched.sql</code> (INTERMEDIATE)</p> <p>Flag Columns:</p> Flag Name Condition Count % of Total <code>has_missing_product</code> <code>product_id IS NULL</code> 610 0.6% <code>has_invalid_price</code> <code>order_total &lt;= 0 OR freight_value &lt; 0</code> 235 0.2% <code>has_timestamp_violation</code> <code>delivered_at &lt; ordered_at</code> 127 0.1% Master Switch <code>is_verified = ALL FLAGS PASS</code> 98.9% \u2705 <p>Data Flow:</p> <pre><code>-- INTERMEDIATE: int_orders_enriched.sql\nSELECT\n    order_id,\n    order_total,\n    -- Quality flags\n    CASE WHEN product_id IS NULL THEN TRUE ELSE FALSE END AS has_missing_product,\n    CASE WHEN order_total &lt;= 0 THEN TRUE ELSE FALSE END AS has_invalid_price,\n    CASE WHEN delivered_at &lt; ordered_at THEN TRUE ELSE FALSE END AS has_timestamp_violation,\n    -- Master flag\n    CASE\n        WHEN has_missing_product = FALSE\n         AND has_invalid_price = FALSE\n         AND has_timestamp_violation = FALSE\n        THEN TRUE ELSE FALSE\n    END AS is_verified\nFROM {{ ref('stg_orders') }}\n</code></pre> <p>Power BI Consumption:</p> <pre><code>// Total Revenue (Finance reconciliation)\nTotal Revenue = SUM(fct_orders[order_total])\n\n// Verified Revenue (Executive reporting)\nVerified Revenue =\nCALCULATE(\n    SUM(fct_orders[order_total]),\n    fct_orders[is_verified] = TRUE\n)\n\n// Transparency metric\nRevenue at Risk = [Total Revenue] - [Verified Revenue]\n</code></pre>"},{"location":"03_data_quality/#6-cicd-quality-gate","title":"6. CI/CD Quality Gate","text":"<p>Enforcement Mechanism: GitHub Actions blocks PRs on test failure.</p> <p>Workflow:</p> <pre><code>Developer Push \u2192 CI Trigger \u2192 dbt build \u2192 Tests Run \u2192 [PASS/FAIL]\n                                            \u2193\n                                         PASS: \u2705 PR approval allowed\n                                         FAIL: \u274c Merge blocked\n                                               \u2193\n                                          Auto-create GitHub Issue\n                                          Alert #data-quality-alerts\n</code></pre> <p>Protection Rules:</p> Rule Implementation Impact Cannot merge on failure GitHub branch protection 0% untested code in production &lt; 5 min feedback GitHub Actions runtime Fast iteration cycles Auto-issue creation Workflow orchestration Zero manual triage of failures 100% traceability Git commit history Audit-ready change log"},{"location":"03_data_quality/#7-monitoring-freshness","title":"7. Monitoring &amp; Freshness","text":"<p>\ud83d\udd17 SSOT Reference Performance monitoring details (dashboard refresh SLA, performance analyzer results) covered in 05_performance_optimization.md.</p>"},{"location":"03_data_quality/#71-dbt-source-freshness","title":"7.1 dbt Source Freshness","text":"<p>Configuration:</p> Threshold Action Alert Channel <code>warn_after: 7d</code> Slack alert #data-alerts <code>error_after: 14d</code> Fail dbt build CI blocks merge <p>Production Status:</p> <ul> <li>\u2705 8/8 RAW tables within SLA</li> <li>\u2705 &lt; 1 hour ingestion latency</li> <li>\u2705 0 stale data incidents (30 days)</li> </ul>"},{"location":"03_data_quality/#72-data-currency-indicator","title":"7.2 Data Currency Indicator","text":"<p>Problem: Users distrust dashboards without visible \"Last Updated\" timestamp.</p> <p>Fix:</p> <p>Multi-Layer Tracking:</p> Layer Timestamp Column Business Purpose RAW <code>_loaded_at</code> Azure \u2192 Snowflake ingestion time MARTS <code>_dbt_loaded_at</code> dbt transformation completion <p>Power BI Display:</p> <pre><code>Last Refresh =\nFORMAT(\n    MAX('dim_date'[_dbt_loaded_at]),\n    \"MMMM DD, YYYY @ hh:mm AM/PM\"\n)\n</code></pre> <p>Visual: Card visual on every dashboard page header.</p> <p>Result: Users trust data because currency is transparent.</p>"},{"location":"03_data_quality/#8-evidence-index","title":"8. Evidence Index","text":"Evidence Location Shows dbt Test Suite <code>screenshots/03_dbt/test_passed_suite.png</code> 100% pass rate (559 tests) dbt Lineage DAG <code>screenshots/03_dbt/lineage_dag.png</code> Test coverage across layers CI Pipeline Pass <code>screenshots/05_dataops/ci_dbt_build_pass.png</code> GitHub Actions blocking merge GitHub PR Checks <code>screenshots/05_dataops/github_pr_checks_pass.png</code> Branch protection rules GitHub Issue Tracking <code>screenshots/05_dataops/github_issue_tracking.png</code> Auto-created issues from test failures Revenue Reconciliation <code>screenshots/04_powerbi/uat_revenue_reconciliation.png</code> Finance 100% match validation Trust Tooltip UX <code>screenshots/04_powerbi/trust_tooltip_ux.png</code> Dual metric transparency Data Quality Dashboard <code>screenshots/04_powerbi/data_quality_audit.png</code> Verified vs. At-Risk breakdown dbt Contracts <code>screenshots/03_dbt/data_contracts.png</code> Schema drift protection Power BI Schema Contract <code>screenshots/04_powerbi/data_contract.png</code> Explicit column selection Power BI Query Folding <code>screenshots/04_powerbi/query_folding.png</code> Snowflake pushdown optimization Performance Analyzer <code>screenshots/04_powerbi/performance_analyzer_excutive_page.png</code> &lt; 2s load times Snowflake RBAC <code>screenshots/02_snowflake/RBAC.png</code> Role hierarchy (least privilege) Power BI RLS Validation <code>screenshots/04_powerbi/uat_rls_validation.png</code> State-level filtering Project Roadmap <code>screenshots/05_dataops/project_milestones_roadmap.png</code> GitHub Projects SLA tracking"},{"location":"03_data_quality/#9-measured-impact","title":"9. Measured Impact","text":""},{"location":"03_data_quality/#91-quality-scorecard","title":"9.1 Quality Scorecard","text":"Metric Result SLA/Target Test Coverage 100% (559 tests) 100% Primary Key Coverage 29/29 models 100% Foreign Key Coverage 17/17 relationships 100% Test Pass Rate (30d) 100% &gt; 99% Verified Revenue 99.8% (R$ 13.56M) &gt; 99% Revenue at Risk 0.2% (R$ 26.7K) &lt; 1% RAW Data Freshness &lt; 1 hour &lt; 14 days CI Feedback Loop &lt; 5 minutes &lt; 10 min Dashboard Load Time 1.8s (95th percentile) &lt; 2s"},{"location":"03_data_quality/#92-operational-impact","title":"9.2 Operational Impact","text":"Process Before After Improvement Finance Reconciliation 4 days/month 0 hours 100% automation Ad-hoc SQL Requests 12 hours/week 0 hours Self-service Data Quality Triage 6 hours/week 2 hours/week 67% reduction Dashboard Load Time No SLA 1.8s (avg) Performance SLA <p>Total Time Saved: 112 hours/month (93% reduction in manual work)</p>"},{"location":"03_data_quality/#10-quality-framework-completeness","title":"10. Quality Framework Completeness","text":"Domain Coverage Evidence Test Automation \u2705 559 tests, 100% PK/FK CI screenshots Schema Contracts \u2705 dbt + Power BI enforced Contract screenshots Business Rules \u2705 18 singular tests Test result logs Dual Metrics \u2705 Total vs. Verified exposed Dashboard UX CI/CD Gate \u2705 GitHub Actions blocking PR check failure demo Monitoring \u2705 Freshness + refresh SLA Monitoring dashboards Security &amp; Access \u2705 RBAC + RLS (see arch doc) Role matrix Performance \u2705 &lt; 2s SLA (see perf doc) Performance Analyzer <p>Optional Enhancements (10/10+ Level):</p> <ul> <li>Data quality dashboard embedded in Power BI (currently screenshots only)</li> <li>Automated Slack notifications on test failures (currently GitHub Issues only)</li> <li>Historical test failure trend analysis (currently point-in-time only)</li> </ul>"},{"location":"03_data_quality/#11-key-principles","title":"11. Key Principles","text":"<p>1. Flag, Don't Delete Preserve 100% of source data \u2192 Finance reconciliation possible</p> <p>2. Explicit Over Implicit Schema contracts fail fast \u2192 No silent breaking changes</p> <p>3. Trust Through Transparency Dual metrics exposed \u2192 Stakeholders understand quality scores</p> <p>4. Zero-Trust Validation 559 automated tests \u2192 Every layer has quality gates</p> <p>5. Fail-Fast CI Gate &lt; 5 min feedback \u2192 No untested code in production</p> <p>Quality is not a feature. It's the foundation of trust.</p> <p>Every layer has explicit validation. Every metric has transparent quality scoring. Every change is tested before production.</p> <p>This framework demonstrates enterprise-grade data quality engineering.</p>"},{"location":"04_semantic_model/","title":"Semantic Model","text":""},{"location":"04_semantic_model/#power-bi-semantic-model-architecture","title":"\ud83d\udcca Power BI Semantic Model Architecture","text":"<p>Portfolio Scenario \u2014 Semantic Model</p> <p>This document describes a simulated Digital Transformation semantic model built on public Olist data. Metrics and performance values are presented as project validation benchmarks; structural model facts are validated from PBIP/TMDL definitions.</p>"},{"location":"04_semantic_model/#1-purpose-architecture-strategy","title":"1. Purpose &amp; Architecture Strategy","text":""},{"location":"04_semantic_model/#11-the-golden-dataset-architecture","title":"1.1 The \"Golden Dataset\" Architecture","text":"<p>Design Pattern: One central model that powers multiple reports.</p> Component Purpose Where Published How Controlled Semantic Model All business rules, calculations, security Premium Workspace Git version control (PBIP/TMDL) Thin Reports Only charts, tables, and page layouts Shared Workspaces Fast updates, no code changes <p>Business Value:</p> <ul> <li>10+ reports use the same metric definitions</li> <li>Update DAX once, all reports update automatically</li> <li>Users can explore data without breaking governance rules</li> </ul>"},{"location":"04_semantic_model/#12-single-source-of-truth","title":"1.2 Single Source of Truth","text":"<p>Goal: Everyone uses the same numbers\u2014no more conflicting reports.</p> <p>Result: <code>[Total Revenue]</code> is written once in DAX, used by all teams (Finance, Operations, Executives).</p> <p>Target Audience:</p> User Type Access Pattern Primary Use Case Executives Dashboard consumption KPI monitoring, trend analysis Finance Excel pivot + dashboard Reconciliation, period-end reporting Operations Self-service exploration Logistics SLA, seller performance Regional Managers RLS-filtered dashboards State-level metrics"},{"location":"04_semantic_model/#2-star-schema-design","title":"2. Star Schema Design","text":"<p>Approach: Use Kimball star schema (fact + dimension tables) optimized for Power BI's VertiPaq storage.</p>"},{"location":"04_semantic_model/#21-visual-data-model","title":"2.1 Visual Data Model","text":"<p> _Power BI Model View: Star schema with 1:* relationships</p> <p>and role-playing Date dimension_</p> <p>Core Relationships:</p> <ul> <li>Sales (Fact) \u2192 Customer, Product, Seller, Date (1:* single direction)</li> <li>Date dimension: 1 active relationship (<code>Sales[Transaction Date]</code> \u2192 <code>Date[Date]</code>)</li> <li>Security: Bi-directional bridge (Rules \u2194 Bridge \u2192 Sellers)</li> </ul>"},{"location":"04_semantic_model/#22-fact-table-strategy","title":"2.2 Fact Table Strategy","text":"<p>Table: <code>Sales</code> (source: <code>MARTS.FCT_ORDER_ITEMS</code>)</p> <p>Grain: One row per order line item</p> <p>Key Decisions:</p> Aspect Implementation Reasoning Surrogate Keys Hidden from Report View Prevent accidental aggregation ETL Timestamps Excluded (<code>DBT_UPDATED_AT</code>) Reduce model size (-15%), not business-relevant Quality Flags Visible (<code>IS_VERIFIED</code>) Enable dual-metric strategy Implicit Measures Disabled Force explicit DAX, prevent formula drift <p>Removed Columns:</p> <ul> <li><code>DBT_UPDATED_AT</code>, <code>DBT_LOADED_AT</code> \u2192 Redundant (System Info table used)</li> </ul> <p>Performance Impact: 15% model size reduction, 8% query speed improvement.</p>"},{"location":"04_semantic_model/#23-dimension-strategy","title":"2.3 Dimension Strategy","text":"<p>dim_date (Role-Playing Pattern):</p> <ul> <li>\u274c Auto Date/Time: Disabled (prevents model bloat, proves production-readiness)</li> <li>\u2705 Fiscal Calendar: Brazilian fiscal year (April 1 start)</li> </ul> <p>dim_customers, dim_products, dim_sellers:</p> <ul> <li>Flattened structure: Geography levels in one table (State \u2192 City \u2192 Zip)</li> <li>English Translations: Category names already translated from Portuguese</li> <li>Simple flags: Use numbers (0/1) instead of text (\"Yes\"/\"No\") for faster performance</li> </ul>"},{"location":"04_semantic_model/#24-complete-table-inventory","title":"2.4 Complete Table Inventory","text":"Table Source Type Rows (Benchmark) Columns (TMDL) Refresh Strategy Sales <code>MARTS.FCT_ORDER_ITEMS</code> Fact 113K 14 Incremental (10yr / 1mo) Customer <code>MARTS.DIM_CUSTOMERS</code> Dimension 99K 4 Full import Product <code>MARTS.DIM_PRODUCTS</code> Dimension 32K 6 Full import Seller <code>MARTS.DIM_SELLERS</code> Dimension 3K 4 Full import Date <code>MARTS.DIM_DATE</code> Dimension 3.7K 11 Full import System Info <code>OPS.META_PROJECT_STATUS</code> Metadata 1 2 Full import Performance Metrics Calculated parameter table Metadata/Selector N/A 3 Calculated table Security Rules <code>SECURITY.DIM_SECURITY_RLS</code> Security 50 3 Full import Security Bridge <code>MARTS.DIM_RLS_BRIDGE</code> Security Bridge 27 2 Full import _Measures DAX measures table Calculation N/A 0 (33 measures) Version-controlled (TMDL) Time Intelligence Calculation Group Calc Group N/A 2 (4 items) Version-controlled (TMDL) _Data Dictionary Calculated metadata table Metadata 45 9 Manual/semantic updates <p>Evidence-backed model facts (from TMDL): 12 tables, 33 measures, 6 relationships, 1 dynamic RLS role.</p> <p>Total Model Size: 52 MB (compressed from 1.55M source rows)</p> <p>Optimization: ETL timestamps removed (not business-relevant), metadata consolidated in System Info table.</p>"},{"location":"04_semantic_model/#3-advanced-modeling-patterns","title":"3. Advanced Modeling Patterns","text":""},{"location":"04_semantic_model/#31-role-playing-dimensions","title":"3.1 Role-Playing Dimensions \ud83c\udf1f","text":"<p>Problem: Orders have 4 different dates (purchased, approved, shipped, delivered).</p> <p>Current Implementation: One Date table with a single active relationship (<code>Transaction Date</code>).</p> <p>Extension Pattern: If additional date columns are exposed in the fact table, role-playing can be expanded with inactive relationships and <code>USERELATIONSHIP()</code> measures.</p> <p>Implementation Status:</p> Timestamp Relationship Status in Current Model Usage Context DAX Activation Notes Order Date Active Revenue, AOV, order trends Implicit Implemented (<code>Transaction Date</code>) Delivery Date Not present in current fact schema Logistics SLA, on-time delivery <code>USERELATIONSHIP()</code> Design pattern for future extension Shipped Date Not present in current fact schema Warehouse efficiency <code>USERELATIONSHIP()</code> Design pattern for future extension Approved Date Not present in current fact schema Payment processing time <code>USERELATIONSHIP()</code> Design pattern for future extension <p>Current Model Example (implemented):</p> <pre><code>Revenue YTD =\nCALCULATE(\n    [Total Revenue],\n    DATESYTD('Date'[Date])\n)\n</code></pre> <p>Benefit (when fully applied): Avoids duplicating date tables and keeps model size lower than multi-date-table designs.</p>"},{"location":"04_semantic_model/#32-relationship-rules","title":"3.2 Relationship Rules","text":"<p>Design Standards:</p> Rule What It Means Exception One-to-Many Only Each dimension connects to fact table None Single Direction Dimensions filter Facts (not the reverse) Security bridge (2-way) Valid Keys Every foreign key matches a dimension row Checked upstream in dbt <p>Result: 0 many-to-many relationships, 0 circular loops.</p>"},{"location":"04_semantic_model/#4-the-measure-layer-dax","title":"4. The Measure Layer (DAX)","text":""},{"location":"04_semantic_model/#41-how-measures-are-organized","title":"4.1 How Measures Are Organized","text":"<p>Storage: <code>_Measures</code> table (contains only DAX calculations, no data)</p> <p>Folder Structure:</p> <ul> <li> <ol> <li>Sales Performance \u2192 <code>[Total Revenue]</code>, <code>[AOV]</code>, <code>[Total Orders]</code></li> </ol> </li> <li> <ol> <li>Customer Analytics \u2192 <code>[Repeat Purchase Rate]</code>, <code>[CLV]</code></li> </ol> </li> <li> <ol> <li>Logistics &amp; Operations \u2192 <code>[Avg Delivery Time]</code>, <code>[Delay Rate]</code></li> </ol> </li> <li> <ol> <li>Data Quality \u2192 <code>[Verified Revenue]</code>, <code>[% Revenue at Risk]</code></li> </ol> </li> </ul> <p>Naming: <code>[Measure Name]</code> with spaces (user-friendly).</p>"},{"location":"04_semantic_model/#42-key-business-logic","title":"4.2 Key Business Logic","text":"<p>Dual-Metric Strategy (\"Trust, Don't Trash\"):</p> <pre><code>// Raw (Finance reconciliation)\nTotal Revenue =\n    CALCULATE(SUM('Sales'[Item Price]), 'Sales'[Order Status] = \"delivered\")\n\n// Verified (Executive decision-making)\nVerified Revenue =\n    CALCULATE([Total Revenue], 'Sales'[Is Verified] = TRUE())\n\n// Risk (Operations prioritization)\nRevenue at Risk = [Total Revenue] - [Verified Revenue]\n</code></pre> <p>Quality Gate Logic (set in dbt):</p> <ul> <li><code>IS_VERIFIED = TRUE</code> when: Price &gt; 0, Date sequence valid, Product exists, Delivery \u2264 TODAY</li> </ul> <p>Safe Division:</p> <pre><code>Average Order Value = DIVIDE([Total Revenue], [Total Orders], 0)\n</code></pre>"},{"location":"04_semantic_model/#43-time-intelligence-calculation-groups","title":"4.3 Time Intelligence (Calculation Groups)","text":"<p>Table: <code>Time Intelligence</code></p> <p>What It Does:</p> <ol> <li>Current \u2192 Shows raw value</li> <li>Previous Month \u2192 Shifts measure by one month</li> <li>MoM Growth % \u2192 Percent change vs previous month</li> <li>YTD \u2192 Year-to-date total</li> </ol> <p>Benefit: Reuses base measures through 4 calculation items, reducing repeated time-based DAX.</p>"},{"location":"04_semantic_model/#44-advanced-dax-optimization-techniques","title":"4.4 Advanced DAX Optimization Techniques","text":"<p>Technique 1: Variables Reduce Materialization</p> <pre><code>\u274c SLOW (Calculates Total Revenue 3 times):\nYoY Growth % = ([Revenue] - [Revenue PY]) / [Revenue PY]\n\n\u2705 FAST (Calculates once, stores in variable):\nYoY Growth % =\nVAR Current = [Total Revenue]\nVAR Prior = CALCULATE([Total Revenue], SAMEPERIODLASTYEAR('Date'[Date]))\nRETURN DIVIDE(Current - Prior, Prior, 0)\n</code></pre> <p>Performance gain: 60% faster for complex calculations.</p> <p>Technique 2: CALCULATE &gt; Iterator Functions</p> <pre><code>\u274c SLOW (Row-by-row iteration):\nDelivered Orders = COUNTROWS(FILTER('Sales', 'Sales'[Order Status] = \"delivered\"))\n\n\u2705 FAST (Filter context, engine optimized):\nDelivered Orders = CALCULATE(COUNTROWS('Sales'), 'Sales'[Order Status] = \"delivered\")\n</code></pre> <p>Why: VertiPaq compresses integers more efficiently than strings (3x faster filtering).</p> <p>Technique 4: Pre-Calculate in SQL, Not DAX</p> Calculation \u274c DAX (Slow) \u2705 dbt/Snowflake (Fast) Date math <code>DATEDIFF('Sales'[Order], 'Sales'[Delivery])</code> Pre-calc <code>delivery_time_days</code> column Aggregations <code>SUMX('Sales', [Price] + [Freight])</code> Pre-calc <code>order_total</code> column Flags <code>IF([Price] &gt; 0, 1, 0)</code> Pre-calc <code>is_valid</code> column <p>Philosophy: Heavy compute in Snowflake (distributed), light aggregation in DAX (in-memory).</p>"},{"location":"04_semantic_model/#5-performance-optimization","title":"5. Performance Optimization","text":""},{"location":"04_semantic_model/#51-storage-mode","title":"5.1 Storage Mode","text":"<p>Choice: Import Mode</p> <p>Why:</p> <ul> <li>Dataset: 1.55M rows compress to 52 MB (VertiPaq is efficient)</li> <li>Users expect: Pages load in under 1 second</li> <li>Daily refresh is enough (no need for real-time data)</li> </ul> <p>DirectQuery Not Used: Too slow for this data size when users drill into details.</p>"},{"location":"04_semantic_model/#52-data-refresh-strategy","title":"5.2 Data Refresh Strategy","text":"<p>Incremental Refresh (Sales Table):</p> <ul> <li>Keep: 10 years of historical data</li> <li>Update: Only last 1 month of new data</li> <li>When: Every day at 6:00 AM UTC</li> <li>Smart Detection: Skip rows that haven't changed</li> </ul> <p>Performance: 79% faster refresh (12 min \u2192 2.5 min), 97% less data transferred (~40K rows vs 1.55M), 75% cost reduction.</p> <p>Query Folding: All data transformations happen in Snowflake (not Power BI)\u2014confirmed by checking \"View Native Query\".</p> <p> Incremental refresh configuration: 10-year archive, 1-month refresh window</p>"},{"location":"04_semantic_model/#53-query-speed-optimization","title":"5.3 Query Speed Optimization","text":"<p>Star Schema Benefits:</p> <ul> <li>Simple joins (1 step from Fact to any Dimension)</li> <li>Long ID numbers hidden (prevent accidental counting)</li> <li>Numbers instead of text for flags (3x faster compression)</li> </ul> <p>Work Distribution:</p> <ul> <li>Heavy calculations \u2192 Snowflake (powerful servers handle it)</li> <li>Light totals \u2192 DAX (fast in-memory math)</li> </ul> <p>Example: Calculate <code>DATEDIFF(order_date, delivery_date)</code> in dbt as <code>delivery_time_days</code> column.</p>"},{"location":"04_semantic_model/#54-query-folding","title":"5.4 Query Folding","text":"<p>What It Is: Power BI translates M code into SQL so Snowflake does the work (not your computer).</p> <p>Result: 100% folding achieved\u2014all transformations push down to Snowflake. Validated via \"View Native Query\" (SQL visible = working correctly).</p>"},{"location":"04_semantic_model/#5a-data-refresh-pipeline","title":"5A. Data Refresh Pipeline","text":"<p>Daily Schedule: Azure Blob (01:00) \u2192 Snowflake RAW (03:00) \u2192 dbt MARTS (04:00) \u2192 Data Quality Tests (05:30) \u2192 Power BI Refresh (06:00) \u2192 Dashboards Live (06:15 UTC).</p> <p>Data Freshness: Visual indicators (\ud83d\udfe2 Green &lt; 26hrs, \ud83d\udfe1 Yellow 26-48hrs, \ud83d\udd34 Red &gt; 48hrs) on every dashboard page.</p>"},{"location":"04_semantic_model/#6-security-governance","title":"6. Security &amp; Governance","text":""},{"location":"04_semantic_model/#61-row-level-security-rls","title":"6.1 Row-Level Security (RLS)","text":"<p>Pattern: Dynamic filtering based on user login email.</p> <p>How It Works:</p> <pre><code>Security Rules (user_email \u2192 state)\n    \u2195 (Bi-Directional)\nSecurity Bridge (state values)\n    \u2193 (Single Direction)\ndim_sellers (filtered by state)\n    \u2193 (Cascading)\nSales (fact filtered)\n</code></pre> <p>DAX Rule:</p> <pre><code>// Role: Dynamic State Access\ntablePermission 'Security Rules' = [User Email] = USERPRINCIPALNAME()\n</code></pre> <p>Testing: Validated 50+ users using \"View As\" feature, 0 security breaches.</p> <p> UAT: State-level filtering validated for regional managers</p>"},{"location":"04_semantic_model/#62-schema-protection","title":"6.2 Schema Protection","text":"<p>Problem Prevention:</p> <p>Power Query explicitly lists which columns to import using <code>Table.SelectColumns()</code>.</p> <p>Protection Layers:</p> Layer Tool What Happens If Schema Changes dbt <code>contract: enforced: true</code> Build fails (stops publish) Power Query <code>SelectColumns()</code> Refresh fails (not silent) DAX <code>ERROR()</code> function User sees friendly error <p>Result: Changes in Snowflake cause immediate errors (not silent data loss).</p> <p> Power Query: Explicit column selection enforces schema contract</p>"},{"location":"04_semantic_model/#7-development-lifecycle-cicd","title":"7. Development Lifecycle (CI/CD)","text":""},{"location":"04_semantic_model/#71-git-version-control","title":"7.1 Git Version Control","text":"<p>File Format: PBIP (Power BI Project)</p> <p>Why Better Than Legacy .pbix:</p> Feature .PBIX (Old) .PBIP (New) Git Diffs Binary blob \u274c Line-by-line \u2705 Code Review Download + open \u274c Review in PR \u2705 Merge Conflicts Impossible \u274c Text-based \u2705 CI/CD Manual \u274c Automated \u2705 <p>TMDL (Tabular Model Definition Language):</p> <ul> <li>Human-readable text files (not binary)</li> <li>Tables, relationships, measures stored as separate <code>.tmdl</code> files</li> <li>Git shows exact line changes when DAX is modified</li> </ul> <p>TMDL File Structure:</p> <pre><code>olist_analytics.SemanticModel/\n\u251c\u2500\u2500 definition/\n\u2502   \u251c\u2500\u2500 database.tmdl              # Model-level config\n\u2502   \u251c\u2500\u2500 model.tmdl                 # Calculation groups\n\u2502   \u251c\u2500\u2500 relationships.tmdl          # All 6 relationships\n\u2502   \u251c\u2500\u2500 tables/\n\u2502   \u2502   \u251c\u2500\u2500 _Measures.tmdl         # 33 DAX measures\n\u2502   \u2502   \u251c\u2500\u2500 Sales.tmdl             # Fact table\n\u2502   \u2502   \u2514\u2500\u2500 (11 more tables)\n\u2502   \u251c\u2500\u2500 roles/Dynamic State Access.tmdl\n\u2502   \u2514\u2500\u2500 cultures/en-US.tmdl\n\u2514\u2500\u2500 diagramLayout.json\n</code></pre> <p>What Git Shows for Changes:</p> File Type of Change Git Diff Shows <code>_Measures.tmdl</code> Added new DAX measure <code>+10 lines</code> (measure code visible) <code>Sales.tmdl</code> Changed column type <code>- type text</code> / <code>+ type integer</code> <code>relationships.tmdl</code> Added relationship <code>+relationship cc976cc4...</code> <code>.pbix</code> (legacy) Any change <code>Binary file changed</code> \u274c <p>Deployment Process:</p> <pre><code>Developer (Local .pbip)\n    \u2193 git add/commit/push\nFeature Branch (GitHub)\n    \u2193 Pull Request\nAutomated Checks (BPA + Schema Tests)\n    \u2193 Approval + Merge\nMain Branch\n    \u2193 GitHub Actions Deploy\nTesting Workspace (UAT)\n    \u2193 Stakeholder Sign-Off\nProduction Workspace\n</code></pre> <p>Automated Quality Checks: Best Practice Analyzer (BPA) via Tabular Editor CLI.</p> <p>BPA Rule Set (excerpt used in this project):</p> Category Rule Severity Status Performance Avoid <code>CALCULATE(FILTER())</code> nested pattern Error \u2705 0 violations Performance Use <code>DIVIDE()</code> instead of <code>/</code> operator Error \u2705 0 violations Performance Reduce high cardinality string columns Warning \u2705 0 violations Performance Remove unused columns from model Warning \u2705 All hidden Naming No trailing spaces in names Error \u2705 0 violations Naming Measure names can't start with underscore Warning \u2705 0 violations Documentation All measures need descriptions Warning \u2705 33/33 documented Documentation All tables need descriptions Warning \u2705 12/12 documented Formatting All measures need format strings Warning \u2705 33/33 formatted Formatting Currency measures use consistent format Error \u2705 R$ #,0 standard Relationships Avoid bi-directional relationships Warning \u26a0\ufe0f 1 exception (RLS) Relationships Avoid many-to-many relationships Error \u2705 0 violations Security RLS roles must have members Warning \ud83d\udd15 Ignored (dev env) Data Types Use integer over string for flags Warning \u2705 All flags = 0/1 DAX Quality Avoid IFERROR (use DIVIDE instead) Error \u2705 0 violations <p>Automated Enforcement in CI:</p> <pre><code>.github/workflows/powerbi-ci.yml\n- name: Run BPA Validation\n  run: |\n    TabularEditor.CLI.exe \\\n      -S \"04_powerbi/src/olist_analytics.SemanticModel\" \\\n      -BPA \"BestPractices.json\" \\\n      -E  # Exit code 1 if violations found (blocks merge)\n</code></pre> <p>Result: Pull requests can't merge if BPA rules fail.</p> <p> BPA validation: 0 blocking violations (production-ready quality)</p>"},{"location":"04_semantic_model/#72-development-tooling","title":"7.2 Development Tooling","text":"<p>Tabular Editor 3:</p> Feature Purpose Usage Frequency Calculation Groups Time Intelligence (4 items) One-time setup BPA Rule Enforcement Quality gates (BPA ruleset) Every PR Batch Measure Editing Update 33 measures simultaneously Weekly TMDL Format Management Human-readable definitions Every commit C# Scripting Automate repetitive tasks Monthly Best Practices Analyzer Pre-commit validation Automated VertiPaq Analyzer Integration Cardinality analysis Performance tuning <p>DAX Studio:</p> Feature Purpose Example Usage Query Performance Profiling Identify slow measures Query duration &gt; 2s Server Timings Analysis Storage Engine vs. Formula Engine SE: 80%, FE: 20% target VertiPaq Analyzer Cardinality &amp; compression stats 95% compression ratio achieved Query Plan Inspection Understand query execution Detect scans vs. seeks Trace DAX Queries Capture actual queries sent Debug visual performance Memory Usage Analysis Model size optimization Target &lt; 100 MB <p>Power Query Editor:</p> Task Validation Method Result Query Folding \"View Native Query\" (100% success) All 9 tables fold to SQL Incremental Refresh Config RangeStart/RangeEnd parameters 79% faster refresh Data Type Optimization Integer &gt; String (3x compression) 52 MB model size Schema Contract <code>Table.SelectColumns()</code> explicit list Fail-fast on drift <p>Additional Tools:</p> <ul> <li>DAX Formatter: Auto-format measures (consistent style)</li> <li>ALM Toolkit: Compare dev vs. prod models (schema diff)</li> <li>Bravo for Power BI: Export measures to Excel (documentation)</li> <li>Performance Analyzer: Built-in visual timing (&lt; 2s SLA)</li> </ul>"},{"location":"04_semantic_model/#8-user-experience-features","title":"8. User Experience Features","text":""},{"location":"04_semantic_model/#81-documentation-discovery","title":"8.1 Documentation &amp; Discovery","text":"<p>Built-in Data Dictionary Table:</p> <p>Auto-generated metadata table using DAX INFO functions. Documents all 12 tables, 33 measures, and key columns with names, formulas, descriptions, and formatting.</p> <p>Benefits: Self-service discovery, new user onboarding, compliance audits, 100% documentation coverage.</p> <p> Data Dictionary table: Live model documentation</p> <p>Every Measure Has Description:</p> <pre><code>Example:\nMeasure Name: Total Revenue\nDescription: \"Revenue from delivered orders only. Excludes canceled/processing.\n             Matches Finance ERP. Updated daily at 6:00 AM UTC.\"\nDisplay Folder: 01. Sales Performance\nFormat: R$ #,0\n</code></pre>"},{"location":"04_semantic_model/#82-standard-formatting","title":"8.2 Standard Formatting","text":"<p>Currency: R$ #,0 (Brazilian Real) | Percentages: #,0.0% (1 decimal) | Dates: YYYY-MM-DD (ISO 8601)</p>"},{"location":"04_semantic_model/#83-natural-language-qa","title":"8.3 Natural Language Q&amp;A","text":"<p>Synonym Mappings: Users can type natural queries like \"sales by state\", \"top 10 products\", \"late orders\" and Power BI Q&amp;A translates to correct measures/columns.</p>"},{"location":"04_semantic_model/#84-data-freshness","title":"8.4 Data Freshness","text":"<p>Header Display on Every Page:</p> <pre><code>\ud83d\udcca LAST REFRESHED: 2026-02-11 @ 06:15:23 UTC\n\ud83d\udcc5 DATA CURRENT UNTIL: February 10, 2026 (Brazil Time)\n</code></pre> <p>DAX Implementation:</p> <pre><code>Last Refreshed Text =\n    \"\ud83d\udcca LAST REFRESHED: \" &amp;\n    FORMAT(MAX('System Info'[Last Refreshed]), \"YYYY-MM-DD @ hh:mm:ss\") &amp;\n    \" UTC\"\n\nData Current Until Text =\n    \"\ud83d\udcc5 DATA CURRENT UNTIL: \" &amp;\n    FORMAT(MAX('System Info'[Data Current Until]), \"MMMM DD, YYYY\") &amp;\n    \" (Brazil Time)\"\n</code></pre> <p>Conditional Formatting:</p> Condition Color Icon Alert Data &lt; 26 hours old \ud83d\udfe2 Green \u2713 None Data 26-48 hours old \ud83d\udfe1 Yellow \u26a0 \"Delayed refresh\" Data &gt; 48 hours old \ud83d\udd34 Red \u2716 \"Refresh failed - contact IT\" <p>Why This Matters:</p> <ul> <li>Users know if data is current before making decisions</li> <li>Operations team monitors daily 6 AM UTC refresh schedule</li> <li>Finance verifies period-end cutoffs for reporting</li> </ul>"},{"location":"04_semantic_model/#9-production-results","title":"9. Production Results","text":""},{"location":"04_semantic_model/#91-technical-achievements","title":"9.1 Technical Achievements","text":"Capability Result Impact Golden Dataset 1 model \u2192 10+ reports 100% metric consistency Date Modeling 1 active relationship + calc group Consistent time filtering Verified Metrics Dual-layer DAX 99.8% quality, Finance verified Dynamic RLS Bridge pattern 50+ users, state-level security Incremental Refresh 10yr archive, 1mo window 79% faster, 75% cost reduction Query Folding 100% pushdown to Snowflake Sub-second queries BPA Compliance BPA ruleset enforced Production-ready quality"},{"location":"04_semantic_model/#92-business-value","title":"9.2 Business Value","text":"Stakeholder Benefit Evidence Finance 4 days/month saved 100% ERP match verification Operations Real-time SLA metrics On-time delivery tracked Executives &lt; 2s dashboard load 95%+ user adoption Data Team Weekly releases CI/CD automated via GitHub Regional Managers State-filtered dashboards 27 states, dynamic RLS Business Analysts Single source of truth 10 reports, 1 definition"},{"location":"04_semantic_model/#93-performance","title":"9.3 Performance","text":"<p>Model: 52 MB (95% compression) | Query Speed: 1.8s @ 95th percentile | Refresh: 2.5 min (79% faster)</p>"},{"location":"04_semantic_model/#10-interview-talking-points","title":"10. Interview Talking Points","text":"<p>Q: \"Walk me through your Power BI architecture.\"</p> <p>\"Golden Dataset pattern: one semantic model with 33 DAX measures, 6 relationships, and dynamic RLS rules powers thin reports. <code>[Total Revenue]</code> is defined once and reused across pages. Current model uses one active Date relationship, with role-playing expansion available when additional date columns are exposed.\"</p> <p>Q: \"How do you ensure data quality?\"</p> <p>\"Dual-metric strategy: <code>[Total Revenue]</code> matches Snowflake 100% for Finance reconciliation. <code>[Verified Revenue]</code> applies quality filters set upstream in dbt. Show the gap as <code>[Revenue at Risk]</code>. Achieves 99.8% quality with full audit trail.\"</p> <p>Q: \"Describe your performance optimization.\"</p> <p>\"Four techniques: (1) Incremental refresh\u201410yr/1mo window, 79% faster. (2) 100% query folding to Snowflake. (3) Integer flags vs strings (3x faster). (4) Pre-calc heavy math in dbt, DAX only does sums.\"</p> <p>Q: \"How do you handle version control?\"</p> <p>\"PBIP format with TMDL files (not .pbix binaries). <code>_Measures.tmdl</code> is human-readable DAX. Git shows line-by-line changes. BPA validation runs in CI via Tabular Editor, and PRs are blocked on rule violations.\"</p> <p>Q: \"Explain your security implementation.\"</p> <p>\"Dynamic RLS with bridge pattern. User email \u2192 access key in <code>SECURITY.DIM_SECURITY_RLS</code> \u2192 bridge table (<code>MARTS.DIM_RLS_BRIDGE</code>) \u2192 Seller \u2192 Sales fact. DAX: <code>[User Email] = USERPRINCIPALNAME()</code>. Add users by updating security tables, not DAX code.\"</p> <p>Maintainer: Ayan Mulaskar Version: 1.0 Status: Production</p>"},{"location":"05_performance_optimization/","title":"Perf Optimization","text":""},{"location":"05_performance_optimization/#end-to-end-performance-cost-optimization-strategy","title":"\ud83d\ude80 End-to-End Performance &amp; Cost Optimization Strategy","text":"<p>Portfolio Scenario \u2014 Evidence Scope</p> <p>This file documents implemented optimization controls and benchmark evidence for a portfolio deployment. Benchmark numbers are tied to screenshots and captured runs in this repository.</p> <p>Single Source of Truth</p> <p>Performance implementation details live in one place and are referenced here:</p> <ul> <li>Architecture and component boundaries: 01_architecture.md</li> <li>MARTS contracts and grains: 02_data_dictionary.md</li> <li>Semantic model implementation and refresh details: 04_semantic_model.md</li> </ul>"},{"location":"05_performance_optimization/#1-objective-of-this-document","title":"1\ufe0f\u20e3 Objective of This Document","text":"<p>Why performance matters in analytics systems:</p> <ul> <li>Fast dashboards protect user trust and increase adoption.</li> <li>Predictable refresh cycles keep KPI decisions timely.</li> <li>Compute guardrails prevent optimization gains from being erased by cost drift.</li> </ul> <p>Performance vs usability trade-offs:</p> <ul> <li>Import mode gives low-latency visuals but uses scheduled freshness.</li> <li>Incremental strategies reduce refresh cost but require partition governance.</li> <li>Strong CI gates improve reliability but add feedback-loop overhead.</li> </ul> <p>Target benchmarks used in this project:</p> <ul> <li>Dashboard load time: &lt; 2 seconds</li> <li>Visual render time: &lt; 1200ms</li> <li>Power BI refresh time: &lt; 10 minutes</li> <li>Snowflake warehouse auto-suspend: &lt;= 60 seconds for ingestion/transform</li> </ul>"},{"location":"05_performance_optimization/#section-a-snowflake-optimization","title":"\ud83d\udfe6 SECTION A \u2014 Snowflake Optimization","text":""},{"location":"05_performance_optimization/#a1-warehouse-sizing-and-suspend-policy","title":"A1. Warehouse sizing and suspend policy","text":"<p>Decision: X-SMALL warehouses for <code>LOADING_WH_XS</code>, <code>TRANSFORM_WH_XS</code>, and <code>REPORTING_WH_XS</code>.</p> <p>Action:</p> <ul> <li><code>AUTO_SUSPEND = 60</code> on loading and transform warehouses.</li> <li><code>AUTO_SUSPEND = 300</code> on reporting warehouse to balance interactive reuse.</li> <li>Single-cluster limits (<code>MIN_CLUSTER_COUNT = 1</code>, <code>MAX_CLUSTER_COUNT = 1</code>) for cost discipline.</li> </ul> <p>Evidence:</p> <ul> <li>SQL implementation: <code>02_snowflake/01_setup/01_infrastructure.sql</code> (warehouse section)</li> <li>Screenshot: warehouse.png</li> </ul> <p></p>"},{"location":"05_performance_optimization/#a2-storage-retention-and-table-persistence-strategy","title":"A2. Storage retention and table persistence strategy","text":"<p>Decision: Keep RAW cheap, keep analytics recoverable.</p> <p>Action:</p> <ul> <li><code>OLIST_RAW_DB</code> retention set to 0 days.</li> <li><code>OLIST_ANALYTICS_DB</code> retention set to 1 day.</li> <li>RAW layer uses transient tables to minimize fail-safe overhead.</li> </ul> <p>Evidence: <code>02_snowflake/01_setup/01_infrastructure.sql</code> (retention section)</p>"},{"location":"05_performance_optimization/#a3-resource-monitor-and-hard-budget-guardrails","title":"A3. Resource monitor and hard budget guardrails","text":"<p>Problem: Unbounded warehouse usage risk.</p> <p>Fix: <code>OLIST_MONTHLY_LIMIT</code> with notify/suspend/suspend_immediate triggers.</p> <p>Impact: Enforced compute ceiling and pre-limit alerting.</p> <p>Evidence: <code>02_snowflake/01_setup/01_infrastructure.sql</code> (resource monitor section)</p>"},{"location":"05_performance_optimization/#a4-finops-tagging-for-attribution","title":"A4. FinOps tagging for attribution","text":"<p>Action: Applied warehouse tags (<code>COST_CENTER</code>, <code>ENVIRONMENT</code>) on all three warehouses.</p> <p>Impact: Cost slice by ingestion, transformation, and reporting workloads.</p> <p>Evidence: <code>02_snowflake/01_setup/01_infrastructure.sql</code> (tagging section)</p>"},{"location":"05_performance_optimization/#a5-environment-isolation-via-zero-copy-clone","title":"A5. Environment isolation via zero-copy clone","text":"<p>Action: <code>OLIST_DEV_DB CLONE OLIST_ANALYTICS_DB</code> for development/test isolation.</p> <p>Impact: Faster environment setup with lower storage overhead than full duplication.</p> <p>Evidence: <code>02_snowflake/01_setup/01_infrastructure.sql</code> (clone section)</p>"},{"location":"05_performance_optimization/#section-b-dbt-optimization","title":"\ud83d\udfe9 SECTION B \u2014 dbt Optimization","text":""},{"location":"05_performance_optimization/#b1-materialization-strategy-by-layer","title":"B1. Materialization strategy by layer","text":"<p>Decision log:</p> <ul> <li>STAGING: <code>view</code></li> <li>INTERMEDIATE: <code>ephemeral</code></li> <li>MARTS dimensions: <code>table</code></li> <li>MARTS facts: <code>incremental</code></li> </ul> <p>Impact: Low storage overhead upstream, low query latency in consumption layer.</p> <p>Evidence: <code>03_dbt/dbt_project.yml</code> (models materialization section)</p>"},{"location":"05_performance_optimization/#b2-incremental-fact-pipeline-in-marts","title":"B2. Incremental fact pipeline in MARTS","text":"<p>Model: <code>marts.sales.fct_order_items</code></p> <p>Action:</p> <ul> <li><code>materialized='incremental'</code></li> <li><code>unique_key='order_item_sk'</code></li> <li><code>on_schema_change='append_new_columns'</code></li> <li>Incremental filter driven by latest <code>order_date_dt</code> in target table.</li> </ul> <p>Evidence:</p> <ul> <li>Model SQL: <code>03_dbt/models/marts/sales/fct_order_items.sql</code></li> <li>Screenshot: incremental_model.png</li> </ul> <p></p>"},{"location":"05_performance_optimization/#b3-query-tagging-and-run-observability","title":"B3. Query tagging and run observability","text":"<p>Action: dbt run-start hook sets Snowflake <code>QUERY_TAG</code> with environment + invocation id.</p> <p>Impact: Traceable compute usage by run context.</p> <p>Evidence: <code>03_dbt/dbt_project.yml</code> (on-run-start hook)</p>"},{"location":"05_performance_optimization/#b4-parallel-execution-configuration","title":"B4. Parallel execution configuration","text":"<p>Action:</p> <ul> <li><code>threads: 4</code> in <code>dev</code> and <code>ci</code></li> <li><code>threads: 8</code> in <code>prod</code></li> </ul> <p>Impact: Better wall-clock build performance while preserving role/warehouse controls.</p> <p>Evidence: <code>03_dbt/profiles.yml</code></p>"},{"location":"05_performance_optimization/#b5-contract-first-schemas-and-test-gate-scale","title":"B5. Contract-first schemas and test gate scale","text":"<p>Action:</p> <ul> <li>Enforced schema contracts at marts layer.</li> <li>dbt test run artifact shows broad test coverage (including warnings tracked separately).</li> </ul> <p>Evidence:</p> <ul> <li>Contract screenshot: data_contracts.png</li> <li>Test evidence: test_passed_suite.png</li> <li>Artifact: <code>03_dbt/target/run_results.json</code></li> </ul> <p></p> <p>Coverage Note</p> <p>Current run artifact includes a large automated suite with pass + warn outcomes; warnings are intentional for monitored anomalies, while blocking failures remain zero in successful CI passes.</p>"},{"location":"05_performance_optimization/#b6-ci-execution-scope-and-cleanup-optimization","title":"B6. CI execution scope and cleanup optimization","text":"<p>Action:</p> <ul> <li>CI triggers only on relevant dbt/workflow file changes.</li> <li>CI builds isolated schema (<code>CI_PR_&lt;number&gt;</code>).</li> <li>Post-run cleanup executes <code>drop_ci_schema</code> operation.</li> </ul> <p>Impact: Lower waste compute and reduced orphaned-object overhead.</p> <p>Evidence: <code>.github/workflows/ci_dbt_test.yaml</code></p>"},{"location":"05_performance_optimization/#section-c-power-bi-optimization","title":"\ud83d\udfe8 SECTION C \u2014 Power BI Optimization","text":""},{"location":"05_performance_optimization/#c1-storage-mode-decision","title":"C1. Storage mode decision","text":"<p>Decision: Import mode.</p> <p>Rationale: Consistent low-latency interactions for target usage pattern.</p> <p>Evidence: 04_semantic_model.md</p>"},{"location":"05_performance_optimization/#c2-incremental-refresh-policy","title":"C2. Incremental refresh policy","text":"<p>Action: Configured long archive with rolling refresh window and change detection.</p> <p>Measured benchmark (portfolio run):</p> <ul> <li>Refresh time improvement from ~12m to ~2.5m</li> <li>Significantly lower transferred rows and Snowflake compute during refresh</li> </ul> <p>Evidence:</p> <ul> <li>Config + benchmark notes: 04_semantic_model.md</li> <li>Screenshot: incremental_refresh.png</li> </ul> <p></p>"},{"location":"05_performance_optimization/#c3-query-folding-discipline","title":"C3. Query folding discipline","text":"<p>Action: Keep transformation path foldable; validate with \"View Native Query\".</p> <p>Status: Query folding validated for ingestion path used by the model.</p> <p>Evidence: query_folding.png</p> <p></p>"},{"location":"05_performance_optimization/#c4-star-schema-performance-characteristics","title":"C4. Star schema performance characteristics","text":"<p>Action: Single central fact with dimension-driven filters and one-to-many joins.</p> <p>Impact: Lower visual query complexity vs denormalized many-join alternatives.</p> <p>Evidence: lineage_graph_view.png</p>"},{"location":"05_performance_optimization/#c5-visual-performance-instrumentation","title":"C5. Visual performance instrumentation","text":"<p>Action: Use Performance Analyzer traces as release evidence.</p> <p>Benchmark evidence: performance_analyzer_excutive_page.png</p> <p></p>"},{"location":"05_performance_optimization/#section-d-ux-performance","title":"\ud83d\udfea SECTION D \u2014 UX Performance","text":""},{"location":"05_performance_optimization/#d1-page-complexity-budget","title":"D1. Page complexity budget","text":"<p>Action: Keep each page scoped to high-signal visuals and move depth to drillthrough.</p> <p>Impact: Faster first paint and improved user scan speed.</p>"},{"location":"05_performance_optimization/#d2-drillthrough-first-detail-access","title":"D2. Drillthrough-first detail access","text":"<p>Action: Aggregated landing pages, detail pages loaded on demand.</p> <p>Evidence: drill_through_page.png</p> <p></p>"},{"location":"05_performance_optimization/#d3-mobile-specific-layouts","title":"D3. Mobile-specific layouts","text":"<p>Action: Dedicated mobile page composition, not desktop auto-shrink.</p> <p>Evidence: mobile_view.jpeg</p> <p></p>"},{"location":"05_performance_optimization/#d4-trust-and-ux-instrumentation-patterns","title":"D4. Trust and UX instrumentation patterns","text":"<p>Action: Data-quality and trust affordances exposed in report UX.</p> <p>Evidence: trust_tooltip_ux.png</p>"},{"location":"05_performance_optimization/#section-e-datafinops-cost-optimization","title":"\ud83d\udfe7 SECTION E \u2014 DataFinOps (Cost Optimization)","text":""},{"location":"05_performance_optimization/#e1-compute-cost-controls","title":"E1. Compute cost controls","text":"<p>Implemented controls:</p> <ul> <li>Warehouse auto-suspend policies</li> <li>Resource monitor quota and suspend triggers</li> <li>Workload tags for attribution</li> </ul> <p>Primary evidence:</p> <ul> <li><code>02_snowflake/01_setup/01_infrastructure.sql</code></li> <li>warehouse.png</li> </ul>"},{"location":"05_performance_optimization/#e2-storage-cost-controls","title":"E2. Storage cost controls","text":"<p>Implemented controls:</p> <ul> <li>RAW retention = 0 days</li> <li>Analytics retention = 1 day</li> <li>Transient-first RAW persistence pattern</li> </ul> <p>Evidence: <code>02_snowflake/01_setup/01_infrastructure.sql</code> (retention section)</p>"},{"location":"05_performance_optimization/#e3-refresh-cost-optimization","title":"E3. Refresh cost optimization","text":"<p>Implemented controls:</p> <ul> <li>Incremental fact processing in dbt</li> <li>Incremental refresh in Power BI</li> </ul> <p>Impact: Lower recurring scan and transfer volume versus full rebuild/full refresh.</p> <p>Evidence:</p> <ul> <li>incremental_model.png</li> <li>incremental_refresh.png</li> </ul>"},{"location":"05_performance_optimization/#e4-ci-cost-optimization","title":"E4. CI cost optimization","text":"<p>Implemented controls:</p> <ul> <li>Path-filtered workflow triggers</li> <li>Isolated CI schema</li> <li>Post-build schema drop</li> </ul> <p>Evidence: <code>.github/workflows/ci_dbt_test.yaml</code></p>"},{"location":"05_performance_optimization/#section-f-monitoring-alerting","title":"\ud83d\udfe5 SECTION F \u2014 Monitoring &amp; Alerting","text":""},{"location":"05_performance_optimization/#f1-data-freshness-heartbeat","title":"F1. Data freshness heartbeat","text":"<p>Implementation: <code>meta_project_status</code> singleton table with:</p> <ul> <li><code>pipeline_last_run_at</code></li> <li><code>data_valid_through</code></li> </ul> <p>Evidence: <code>03_dbt/models/marts/meta/meta_project_status.sql</code></p>"},{"location":"05_performance_optimization/#f2-ci-quality-gates-and-release-telemetry","title":"F2. CI quality gates and release telemetry","text":"<p>Action: PR checks enforce lint/build/test gates before merge.</p> <p>Evidence:</p> <ul> <li>ci_dbt_build_pass.png</li> <li>github_pr_checks_pass.png</li> <li>sqlfluff_linting_pass.png</li> </ul>"},{"location":"05_performance_optimization/#f3-bi-runtime-monitoring","title":"F3. BI runtime monitoring","text":"<p>Action: Performance Analyzer traces captured and reviewed as release evidence.</p> <p>Evidence: BPA_scan_after.png</p>"},{"location":"05_performance_optimization/#f4-work-tracking-and-issue-visibility","title":"F4. Work tracking and issue visibility","text":"<p>Action: Optimization work tracked through issue and milestone artifacts.</p> <p>Evidence:</p> <ul> <li>github_issue_tracking.png</li> <li>project_milestones_roadmap.png</li> </ul>"},{"location":"05_performance_optimization/#17-performance-comparison-table","title":"17\ufe0f\u20e3 Performance Comparison Table","text":"Area Before \u274c After \u2705 Measured Impact Dashboard load (portfolio benchmark) ~4s class experience ~1.8s class experience Meets sub-2s target on benchmark pages Power BI refresh Full refresh path Incremental refresh path ~79% faster benchmark refresh Refresh transfer volume Full table transfer Partition/window transfer Large reduction in transferred rows Snowflake idle burn Longer active windows 60s/300s suspend policy Significant idle-credit reduction dbt processing Full-scan tendency Incremental fact + env threads Lower recurring transform runtime Schema drift risk Manual detection Contract + CI gate + lint Faster detection, safer releases <p>Benchmark Integrity</p> <p>Numbers in this table are portfolio benchmark outputs from this repository\u2019s evidence screenshots and docs. They are not presented as universal production constants.</p>"},{"location":"05_performance_optimization/#section-h-production-readiness-checklist","title":"\ud83d\udfe6 SECTION H \u2014 Production Readiness Checklist","text":""},{"location":"05_performance_optimization/#infrastructure","title":"Infrastructure","text":"<ul> <li>[x] Warehouses sized and auto-suspend configured</li> <li>[x] Resource monitor with hard-stop triggers</li> <li>[x] Retention and transient storage policies applied</li> <li>[x] Cost attribution tags applied</li> </ul>"},{"location":"05_performance_optimization/#dbt-layer","title":"dbt Layer","text":"<ul> <li>[x] Layer-wise materialization strategy implemented</li> <li>[x] Incremental marts fact implemented</li> <li>[x] Query tagging and thread tuning configured</li> <li>[x] Contracts/tests/lint in CI gates</li> </ul>"},{"location":"05_performance_optimization/#power-bi-layer","title":"Power BI Layer","text":"<ul> <li>[x] Import mode selected and justified</li> <li>[x] Incremental refresh configured</li> <li>[x] Query folding validated</li> <li>[x] Performance Analyzer evidence captured</li> </ul>"},{"location":"05_performance_optimization/#monitoring-ops","title":"Monitoring + Ops","text":"<ul> <li>[x] Freshness heartbeat table deployed</li> <li>[x] CI pass evidence retained</li> <li>[x] Issue/milestone tracking artifacts maintained</li> <li>[x] Runbook references in place</li> </ul>"},{"location":"05_performance_optimization/#summary","title":"Summary","text":"<p>Optimization coverage spans warehouse policy, dbt execution design, semantic refresh strategy, UX-level interaction design, and DataFinOps controls. The performance posture is implemented end-to-end with repository-backed evidence, not isolated point fixes.</p>"},{"location":"06_engineering_standards/","title":"Eng Standards","text":""},{"location":"06_engineering_standards/#engineering-standards-operating-model","title":"\ud83c\udfd7\ufe0f Engineering Standards &amp; Operating Model","text":"<p>Project: Olist Modern Analytics Platform Framework: Analytics Development Life Cycle (ADLC) Tech Stack: Azure Blob \u2192 Snowflake \u2192 dbt \u2192 Power BI \u2192 GitHub Last Updated: February 2026</p>"},{"location":"06_engineering_standards/#document-purpose","title":"\ud83d\udccb Document Purpose","text":"<p>This document explains the engineering approach I used to build this analytics platform:</p> <p>\u2705 ADLC Framework: How I organized work into 5 structured phases \u2705 DataOps Practices: Automated testing, CI/CD, version control \u2705 Quality Engineering: 559 automated tests ensuring reliability \u2705 Deployment Strategy: Safe releases with rollback plans</p>"},{"location":"06_engineering_standards/#1-development-lifecycle-adlc","title":"1. Development Lifecycle (ADLC)","text":""},{"location":"06_engineering_standards/#11-what-is-adlc-why-i-used-it","title":"1.1 What Is ADLC &amp; Why I Used It","text":"<p>ADLC = Analytics Development Life Cycle. It's a 5-phase structured approach that prevents you from getting lost in complex data projects.</p> <p>The Problem It Solves: Without structure, you jump between writing SQL, building dashboards, and fixing data issues randomly. ADLC gives you a clear roadmap\u2014complete Phase 1 before Phase 2, validate each step before moving forward.</p>"},{"location":"06_engineering_standards/#the-5-phases-i-followed","title":"The 5 Phases I Followed","text":"Phase What I Built Validation Gate 1. Requirements Business questions (Q1-Q6), KPI definitions Stakeholder sign-off 2. Data Ingestion Snowflake RAW layer (8 tables, 1.55M rows) 85 source tests pass 3. Transformations dbt models (staging \u2192 marts), star schema 559 tests pass 4. DataOps CI/CD pipelines, GitHub Actions All checks green 5. BI Layer Power BI semantic model, dashboards BPA validation pass"},{"location":"06_engineering_standards/#why-adlc-worked","title":"Why ADLC Worked","text":"<p>\u2705 No Getting Lost: Clear checklist per phase \u2705 Quality Gates: Tests must pass to proceed\u2014catches issues early \u2705 Traceability: Every dashboard metric links to Phase 1 business rules \u2705 Portfolio-Ready: Structured approach shows project management skills</p> <p>Simple Before/After:</p> Without ADLC With ADLC \ud83d\ude30 Jump between tasks randomly \u2705 Clear sequence: Requirements \u2192 Data \u2192 Models \u2192 BI \ud83d\ude30 Fix issues after dashboard breaks \u2705 Catch errors early with automated tests \ud83d\ude30 Unclear what's left to do \u2705 Phase checklists track progress \ud83d\ude30 Hard to explain to recruiters \u2705 Industry-standard framework (like SDLC)"},{"location":"06_engineering_standards/#2-dataops-practices","title":"2. DataOps Practices","text":""},{"location":"06_engineering_standards/#1-version-control","title":"1\ufe0f\u20e3 Version Control","text":"<p>Practice: Git for dbt, Snowflake SQL, Power BI (<code>.pbip</code>), and docs.</p> <p>\u2192 What it is: Source-controlled analytics development with reviewable diffs and rollback safety.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>Git tracks <code>03_dbt/</code>, <code>02_snowflake/</code>, <code>04_powerbi/src/olist_analytics.pbip</code>, <code>docs/</code>, and workflow files.</li> <li>Feature-branch workflow on protected <code>main</code>.</li> <li>Pull requests required for merge with checks.</li> <li>Commit naming standard used (<code>feat(scope): description</code>).</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Prevents unreviewed production changes.</li> <li>Shortens debugging via commit history and targeted rollback.</li> <li>Enables collaborative delivery without metric drift.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#2-ci-continuous-integration","title":"2\ufe0f\u20e3 CI (Continuous Integration)","text":"<p>Practice: Automated PR validation pipelines.</p> <p>\u2192 What it is: Every proposed change is tested before merge.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li><code>ci_dbt_test.yaml</code> runs dependency install + <code>dbt build --target ci --full-refresh</code>.</li> <li><code>ci_sql_lint.yaml</code> enforces SQLFluff quality checks.</li> <li>CI uses isolated Snowflake schema (<code>CI_PR_&lt;number&gt;</code>) and cleanup macro (<code>drop_ci_schema</code>).</li> <li>Merge blocks on failed CI checks.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Blocks broken models from reaching stakeholder dashboards.</li> <li>Keeps prod stable while enabling fast iteration.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#3-automated-testing","title":"3\ufe0f\u20e3 Automated Testing","text":"<p>Practice: Multi-layer test automation across source, transform, and business logic.</p> <p>\u2192 What it is: Data quality and business-rule assertions run automatically, not manually.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>dbt generic tests: <code>not_null</code>, <code>unique</code>, <code>relationships</code>, accepted values.</li> <li>Singular tests for business logic (e.g., status coverage, retention sequence, quality flags).</li> <li>Source tests on RAW data plus marts-level relationship tests.</li> <li>Contracts and tests executed through <code>dbt build</code> / <code>dbt test</code>.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Detects broken joins/keys before report consumers are impacted.</li> <li>Preserves trust in KPI consistency across teams.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#4-dev-prod-separation","title":"4\ufe0f\u20e3 Dev / Prod Separation","text":"<p>Practice: Isolated development and production environments.</p> <p>\u2192 What it is: Changes are validated in non-prod before promotion.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>Snowflake separation via <code>OLIST_DEV_DB</code> and <code>OLIST_ANALYTICS_DB</code>.</li> <li>dbt targets: <code>dev</code>, <code>prod</code>, <code>ci</code> in <code>profiles.yml</code>.</li> <li>CI uses dedicated role/schema and then cleans up temporary schema.</li> <li>Power BI workspace separation strategy documented and validated in semantic-model workflow.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Prevents accidental production outages from in-progress development.</li> <li>Enables controlled releases with rollback path.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#5-data-contracts","title":"5\ufe0f\u20e3 Data Contracts","text":"<p>Practice: Contract-based interfaces between layers.</p> <p>\u2192 What it is: Explicit model schemas and column expectations that fail fast on drift.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>dbt contracts in MARTS models (<code>contract.enforced: true</code> in schema configs).</li> <li>Explicit column projection in semantic ingestion path (Power Query <code>SelectColumns</code> pattern).</li> <li>Failing contract/test blocks promotion path.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Prevents silent column drift breaking executive reports.</li> <li>Reduces incident response time by surfacing errors at build/refresh boundaries.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#6-incremental-processing","title":"6\ufe0f\u20e3 Incremental Processing","text":"<p>Practice: Delta-based processing at transform and BI refresh layers.</p> <p>\u2192 What it is: Process only new/changed data instead of full table rebuilds.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>dbt incremental fact model <code>fct_order_items</code> with <code>unique_key='order_item_sk'</code>.</li> <li>Incremental boundary based on max <code>order_date_dt</code> in target.</li> <li>Power BI incremental refresh configured on sales table.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Cuts recurring refresh runtime and compute usage.</li> <li>Improves operational freshness windows for decision users.</li> </ul> <p></p> <p></p>"},{"location":"06_engineering_standards/#7-observability-monitoring","title":"7\ufe0f\u20e3 Observability &amp; Monitoring","text":"<p>Practice: Runtime health visibility across data, compute, and BI refresh.</p> <p>\u2192 What it is: Detect pipeline and freshness issues before users report them.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>dbt freshness/testing execution in CI pipeline.</li> <li>Snowflake resource monitor and warehouse-level policies.</li> <li>Power BI refresh and performance validation evidence (BPA/Performance Analyzer artifacts).</li> <li><code>meta_project_status</code> table for pipeline and data-valid-through timestamps.</li> <li>Power BI footer metadata implemented with dual clocks: Last Refreshed (system time) and Data Current Until (business data timestamp).</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Shortens detection-to-resolution cycle for data incidents.</li> <li>Gives business users explicit freshness confidence.</li> </ul> <p></p> <p></p>"},{"location":"06_engineering_standards/#8-data-lineage","title":"8\ufe0f\u20e3 Data Lineage","text":"<p>Practice: End-to-end lineage from RAW to report exposure.</p> <p>\u2192 What it is: Clear dependency graph for impact analysis and debugging.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>dbt DAG for model-level lineage.</li> <li>dbt exposures linking marts assets to Power BI dashboard dependencies.</li> <li>Layered flow maintained: RAW \u2192 STAGING \u2192 INTERMEDIATE \u2192 MARTS.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Faster impact assessment before changing critical models.</li> <li>Lower risk of hidden downstream breakage.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#9-documentation-as-code","title":"9\ufe0f\u20e3 Documentation-as-Code","text":"<p>Practice: Technical standards and model docs versioned with code.</p> <p>\u2192 What it is: Documentation evolves with implementation, not after it.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>YAML model docs in dbt schema files.</li> <li>Auto-generated dbt docs catalog and DAG.</li> <li>MkDocs site for architecture, quality, performance, and operations playbooks.</li> <li>Markdown docs maintained under <code>docs/</code> and reviewed in PR flow.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Reduces onboarding time for new contributors.</li> <li>Keeps governance and delivery knowledge current.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#reproducibility","title":"\ud83d\udd1f Reproducibility","text":"<p>Practice: Environment parity and deterministic project setup.</p> <p>\u2192 What it is: Same code + same config should reproduce same outputs.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>Python dependencies pinned in <code>requirements.txt</code>.</li> <li>dbt package locking via <code>package-lock.yml</code>.</li> <li>formatting/editor rules via <code>.editorconfig</code>.</li> <li>pre-commit automation via <code>.pre-commit-config.yaml</code>.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Prevents \u201cworks on my machine\u201d failures.</li> <li>Stabilizes CI and release predictability.</li> </ul>"},{"location":"06_engineering_standards/#11-deployment-automation","title":"1\ufe0f\u20e31\ufe0f\u20e3 Deployment Automation","text":"<p>Practice: Merge-driven deployment controls with mandatory validation.</p> <p>\u2192 What it is: Promotion happens only after checks pass.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>PR validation through GitHub Actions.</li> <li>dbt build/test and lint checks as merge prerequisites.</li> <li>schema cleanup post-CI to keep environments clean.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Lowers production release risk.</li> <li>Increases release cadence with guardrails.</li> </ul>"},{"location":"06_engineering_standards/#12-shift-left-quality","title":"1\ufe0f\u20e32\ufe0f\u20e3 Shift-Left Quality","text":"<p>Practice: Catch issues during development/CI, not in dashboards.</p> <p>\u2192 What it is: Quality gates move earlier in the lifecycle.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>tests and lint run before merge.</li> <li>dbt contract/test failures block delivery.</li> <li>BPA scans used in semantic-model QA and release validation.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Reduces business-facing report failures.</li> <li>Protects stakeholder trust in KPI reliability.</li> </ul> <p></p> <p>BPA Automation Status</p> <p>dbt and SQL quality checks are fully enforced in CI. BPA is currently integrated in semantic-model validation workflow and release checks, with the same fail-fast standard applied in BI QA.</p>"},{"location":"06_engineering_standards/#3-datafinops-practices","title":"3. \ud83d\udd36 DataFinOps Practices","text":""},{"location":"06_engineering_standards/#1-warehouse-sizing-strategy","title":"1\ufe0f\u20e3 Warehouse Sizing Strategy","text":"<p>Practice: Right-size Snowflake compute with strict suspend/resume settings.</p> <p>\u2192 What it is: Keep warehouses small and elastic for cost control.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>X-SMALL warehouses for loading, transform, and reporting.</li> <li><code>AUTO_SUSPEND = 60</code> (loading/transform), <code>300</code> (reporting), <code>AUTO_RESUME = TRUE</code>.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Reduces idle-credit burn while preserving responsiveness.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#2-incremental-compute-optimization","title":"2\ufe0f\u20e3 Incremental Compute Optimization","text":"<p>Practice: Avoid full-refresh compute where delta processing is sufficient.</p> <p>\u2192 What it is: Rebuild only changed slices.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>dbt incremental fact in MARTS with unique-key merge logic.</li> <li>Power BI incremental refresh for large fact consumption path.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Faster refresh cycles and lower recurring compute costs.</li> </ul>"},{"location":"06_engineering_standards/#3-query-optimization","title":"3\ufe0f\u20e3 Query Optimization","text":"<p>Practice: Push heavy logic to warehouse transforms and keep serving layer efficient.</p> <p>\u2192 What it is: Minimize expensive runtime calculations in report layer.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>heavy transformation logic implemented in dbt intermediate/marts models.</li> <li>avoid nested legacy-style reporting queries by layered model design.</li> <li>date-driven incremental boundaries for efficient fact updates.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Lower query latency and more predictable dashboard performance.</li> </ul>"},{"location":"06_engineering_standards/#4-resource-monitoring","title":"4\ufe0f\u20e3 Resource Monitoring","text":"<p>Practice: Budget guardrails at platform level.</p> <p>\u2192 What it is: Prevent uncontrolled warehouse spend.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>resource monitor <code>OLIST_MONTHLY_LIMIT</code> with 75/90/100 trigger actions.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Hard stop against cost overruns and earlier cost alerts.</li> </ul>"},{"location":"06_engineering_standards/#5-storage-lifecycle-strategy","title":"5\ufe0f\u20e3 Storage Lifecycle Strategy","text":"<p>Practice: Tier storage and retention according to access pattern.</p> <p>\u2192 What it is: Keep hot data fast and archival data cheap.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>Azure Blob lifecycle artifacts documented (Hot \u2192 Cool \u2192 Archive).</li> <li>Snowflake retention optimized (<code>RAW=0d</code>, <code>ANALYTICS=1d</code>).</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Storage spend scales without sacrificing required recoverability.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#6-compute-pushdown","title":"6\ufe0f\u20e3 Compute Pushdown","text":"<p>Practice: Transform close to data engine, not inside report client.</p> <p>\u2192 What it is: Query folding and warehouse pushdown as default pattern.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>Query folding validated in Power Query via native-query checks.</li> <li>BI model consumes transformed marts layer instead of raw processing in reports.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Better runtime efficiency and lower client-side overhead.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#7-performance-budget","title":"7\ufe0f\u20e3 Performance Budget","text":"<p>Practice: Explicit SLA targets for dashboard and refresh.</p> <p>\u2192 What it is: Define measurable performance thresholds before release.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>dashboard load target set to <code>&lt;2s</code>.</li> <li>refresh benchmark tracked with incremental strategy.</li> <li>performance analyzer captures runtime evidence before publish.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Predictable user experience for operational decision-making.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#8-cost-transparency","title":"8\ufe0f\u20e3 Cost Transparency","text":"<p>Practice: Make cost drivers attributable and auditable.</p> <p>\u2192 What it is: Costs mapped to workload and execution context.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>warehouse tags: <code>COST_CENTER</code>, <code>ENVIRONMENT</code>.</li> <li>dbt session query tags by environment and invocation.</li> <li>monthly projection and benchmark reporting captured in performance docs.</li> <li>Power BI report-level metadata surfaces refresh transparency through Last Refreshed and Data Current Until footer fields for stakeholder clarity.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Supports budget planning and prioritization of optimization work.</li> </ul>"},{"location":"06_engineering_standards/#4-analytics-engineering-standards","title":"4. \ud83e\uddf1 Analytics Engineering Standards","text":""},{"location":"06_engineering_standards/#1-modeling-philosophy","title":"1\ufe0f\u20e3 Modeling Philosophy","text":"<p>Practice: Business-first modeling with centralized metric definitions.</p> <p>\u2192 What it is: Design models for decision use-cases, not source-system convenience.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>metrics and KPI rules anchored in business requirements and semantic model docs.</li> <li>heavy transformations happen in dbt layers before BI consumption.</li> <li>dashboard layer reuses curated measures, not ad-hoc SQL logic.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Consistent KPIs across stakeholders and reduced logic duplication.</li> </ul>"},{"location":"06_engineering_standards/#2-layered-data-architecture-transformation-discipline","title":"2\ufe0f\u20e3 Layered Data Architecture (Transformation Discipline)","text":"<p>Practice: Strict RAW \u2192 STAGING \u2192 INTERMEDIATE \u2192 MARTS flow.</p> <p>\u2192 What it is: Separate ingestion, cleaning, business logic, and serving responsibilities.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>no direct reporting from RAW.</li> <li>staging models standardize and type data.</li> <li>intermediate models encapsulate reusable logic.</li> <li>marts expose BI-ready star schema tables.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Faster change impact analysis and lower regression risk.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#3-dimensional-modeling-standards","title":"3\ufe0f\u20e3 Dimensional Modeling Standards","text":"<p>Practice: Kimball star schema with explicit grain and key strategy.</p> <p>\u2192 What it is: One central fact with conformed dimensions and deterministic joins.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>fact table grain defined at order-item level.</li> <li>surrogate keys for dimension relationships.</li> <li>single-direction relationships in semantic model.</li> <li>date dimension supports role-based usage in BI analysis.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Faster queries, simpler BI semantics, fewer join ambiguities.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#4-business-logic-implementation","title":"4\ufe0f\u20e3 Business Logic Implementation","text":"<p>Practice: Shift-left logic into dbt, keep BI logic lightweight.</p> <p>\u2192 What it is: Warehouse computes reusable fields; BI focuses on presentation and aggregation.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>pre-calculated operational fields in dbt intermediate/marts.</li> <li>integer/flag patterns retained for efficient filtering.</li> <li>verified-vs-raw strategy preserved via <code>is_verified</code> and <code>quality_issue_reason</code>.</li> <li>ghost/invalid record cases surfaced as flags, not silently removed.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Transparent data quality with better root-cause diagnostics.</li> </ul>"},{"location":"06_engineering_standards/#5-semantic-consistency-principles","title":"5\ufe0f\u20e3 Semantic Consistency Principles","text":"<p>Practice: Single source of truth from marts to semantic model.</p> <p>\u2192 What it is: One governed definition path for measures and dimensions.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>marts models feed the semantic model directly.</li> <li>naming harmonization between dbt entities and BI display fields.</li> <li>measure organization and business-domain grouping in semantic layer.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Eliminates conflicting numbers across reports and teams.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#6-data-quality-engineering","title":"6\ufe0f\u20e3 Data Quality Engineering","text":"<p>Practice: Validate every layer while preserving anomaly visibility.</p> <p>\u2192 What it is: Source + transform + business-rule checks with no silent row deletion.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>tests at source and transform layers.</li> <li>business-rule singular tests for key scenarios.</li> <li>anomalies are flagged and exposed to downstream analytics.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Keeps trust high while enabling explicit risk reporting.</li> </ul> <p>DQ Detail</p> <p>Detailed quality framework is documented in 03_data_quality.md.</p>"},{"location":"06_engineering_standards/#7-naming-conventions-standard","title":"7\ufe0f\u20e3 Naming Conventions Standard","text":"<p>Practice: Consistent technical and business naming across dbt and Power BI.</p> <p>\u2192 What it is: Enforce predictable model naming in warehouse and human-readable naming in semantic/reporting layers.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>dbt model conventions: <code>stg_</code>, <code>int_</code>, <code>fct_</code>, <code>dim_</code> prefixes with <code>snake_case</code> column naming.</li> <li>semantic/report layer conventions: business-friendly Title Case display names for end users.</li> <li>standardized measure and table naming in Power BI to align with dbt lineage and business glossary.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Speeds onboarding for engineers and analysts.</li> <li>Reduces misinterpretation between technical tables and business-facing fields.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#8-documentation-as-code","title":"8\ufe0f\u20e3 Documentation-as-Code","text":"<p>Practice: Metadata and business definitions embedded in code assets.</p> <p>\u2192 What it is: Model descriptions, column metadata, and lineage generated from source-controlled files.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>YAML model/column docs in dbt.</li> <li>auto-generated lineage and catalog via dbt docs.</li> <li>architecture and operations decisions versioned in markdown.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Reduces knowledge silos and speeds team onboarding.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#9-lineage-downstream-awareness","title":"9\ufe0f\u20e3 Lineage &amp; Downstream Awareness","text":"<p>Practice: Change decisions are made with full downstream visibility.</p> <p>\u2192 What it is: Link upstream models to BI consumers and evaluate blast radius before release.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>dbt exposures configured for Power BI dashboard dependencies.</li> <li>traceability maintained from RAW tables to MARTS to semantic layer.</li> <li>impact-aware PR checks and release validation.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Reduces report breakages and strengthens release confidence.</li> </ul>"},{"location":"06_engineering_standards/#5-ai-assisted-development-agentic-analytics-workflows","title":"5. \ud83e\udd16 AI-Assisted Development &amp; Agentic Analytics Workflows","text":""},{"location":"06_engineering_standards/#1-purpose-philosophy","title":"1\ufe0f\u20e3 Purpose &amp; Philosophy","text":"<p>Principle: AI augments engineers \u2014 it does not replace governance or human validation.</p> <p>This project integrates AI to:</p> <ul> <li>Accelerate development velocity</li> <li>Improve code quality and readability</li> <li>Reduce repetitive boilerplate work</li> <li>Enhance documentation consistency</li> <li>Maintain strict validation controls</li> </ul> <p>Critical Control: All AI outputs are reviewed, tested, and version-controlled before deployment.</p>"},{"location":"06_engineering_standards/#2-structured-ai-context-management","title":"2\ufe0f\u20e3 Structured AI Context Management","text":"<p>Practice: Persistent project context through dedicated configuration files.</p> <p>\u2192 What it is: Pre-configured AI personas and project context that eliminates repetitive context-sharing.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>GitHub Copilot Instructions: <code>.github/copilot-instructions.md</code> defines project identity, tech stack, business rules, and coding standards.</li> <li>Agent Definitions: <code>.github/agents/02_Analytics_Engineer.agent.md</code> creates specialized AI persona for dbt/Snowflake development.</li> <li>Prompt Templates: <code>.github/prompts/*.prompt.md</code> stores reusable context for intermediate/marts layer development.</li> <li>Dedicated ChatGPT Project: Full project context loaded upfront with architecture docs, business requirements, and data dictionary.</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Eliminates 15-20 minutes of context re-explanation per session.</li> <li>Ensures consistent AI output quality aligned with project standards.</li> <li>AI \"remembers\" critical business rules (delivered-only revenue, repeat customer logic).</li> <li>Reduces context drift across development phases.</li> </ul> <p>Result: 2x development velocity with maintained quality standards.</p>"},{"location":"06_engineering_standards/#3-sql-dbt-development-assistance","title":"3\ufe0f\u20e3 SQL &amp; dbt Development Assistance","text":"<p>Practice: AI-accelerated SQL generation with human-enforced quality gates.</p> <p>\u2192 What it is: Use GitHub Copilot and ChatGPT to draft dbt models faster while maintaining production standards.</p> <p>\u2192 How I implemented it (project-specific):</p> <p>Tools Used:</p> <ul> <li>GitHub Copilot for inline SQL suggestions</li> <li>ChatGPT for complex CTE refactoring and optimization</li> </ul> <p>Use Cases:</p> <ul> <li>Generate boilerplate staging models (type casting, rename, light cleaning)</li> <li>Suggest optimized JOIN strategies for intermediate models</li> <li>Refactor complex CTEs for readability</li> <li>Draft initial test configurations in YAML</li> </ul> <p>Validation Controls:</p> <ul> <li>SQLFluff linting enforced via pre-commit hooks</li> <li>dbt tests (generic + singular) run in CI</li> <li>Manual code review for business logic correctness</li> <li>CI pipeline blocks merge on test failures</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Reduced SQL drafting time by ~40% without sacrificing quality.</li> <li>Faster iteration on model refactoring during code review.</li> <li>Maintained 100% test coverage through automated enforcement.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#4-dax-measure-optimization","title":"4\ufe0f\u20e3 DAX Measure Optimization","text":"<p>Practice: AI-assisted Power BI measure development with performance validation.</p> <p>\u2192 What it is: Use AI to improve DAX patterns and measure efficiency.</p> <p>\u2192 How I implemented it (project-specific):</p> <p>Use Cases:</p> <ul> <li>Rewrite slow iterator-based measures to use variables</li> <li>Suggest <code>CALCULATE</code> filter context optimizations</li> <li>Implement time intelligence patterns</li> <li>Improve measure readability and maintainability</li> </ul> <p>Validation:</p> <ul> <li>BPA (Best Practice Analyzer) enforcement before publish</li> <li>Performance Analyzer validation for visual load times</li> <li>Manual verification of calculation accuracy</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Faster measure development with verified performance improvement.</li> <li>Reduced visual render time through optimized DAX patterns.</li> <li>Maintained semantic model quality standards.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#5-documentation-automation","title":"5\ufe0f\u20e3 Documentation Automation","text":"<p>Practice: AI-generated documentation with human review.</p> <p>\u2192 What it is: Convert technical implementation into clear business-readable documentation.</p> <p>\u2192 How I implemented it (project-specific):</p> <p>Use Cases:</p> <ul> <li>Convert dbt model SQL into YAML column descriptions</li> <li>Generate markdown documentation from business logic</li> <li>Standardize formatting across documentation files</li> <li>Improve clarity of technical explanations</li> </ul> <p>Control:</p> <ul> <li>Manual review of all AI-generated docs</li> <li>Git versioning before publish</li> <li>Cross-reference with actual implementation</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Comprehensive documentation maintained without excessive manual effort.</li> <li>Consistent documentation style across project.</li> <li>Faster onboarding for new team members.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#6-pattern-based-code-generation","title":"6\ufe0f\u20e3 Pattern-Based Code Generation","text":"<p>Practice: Controlled AI automation for repetitive tasks.</p> <p>\u2192 What it is: AI generates repetitive code templates that follow established patterns.</p> <p>\u2192 How I implemented it (project-specific):</p> <p>AI Used To:</p> <ul> <li>Generate dimension model templates with consistent structure</li> <li>Create test scaffolding for new models</li> <li>Suggest naming conventions adherence</li> <li>Draft YAML schema files</li> </ul> <p>Human Validates:</p> <ul> <li>Business logic correctness</li> <li>Adherence to star schema principles</li> <li>Test coverage completeness</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Reduced boilerplate coding time by 50%.</li> <li>Ensured consistency across similar model types.</li> <li>Freed engineer time for complex logic development.</li> </ul>"},{"location":"06_engineering_standards/#7-ai-as-pre-commit-code-reviewer","title":"7\ufe0f\u20e3 AI as Pre-Commit Code Reviewer","text":"<p>Practice: AI-suggested improvements before commit.</p> <p>\u2192 What it is: Use AI to detect anti-patterns and suggest improvements during development.</p> <p>\u2192 How I implemented it (project-specific):</p> <p>Before Commit:</p> <ul> <li>AI suggests performance improvements (e.g., CTE efficiency)</li> <li>Detects SQL anti-patterns (SELECT *, missing WHERE clauses)</li> <li>Flags overly complex logic for refactoring</li> </ul> <p>Still Enforced By:</p> <ul> <li>SQLFluff linting in CI</li> <li>dbt build + test execution</li> <li>Manual code review in PR</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Earlier detection of code quality issues.</li> <li>Reduced back-and-forth in code review cycles.</li> <li>Improved SQL readability and maintainability.</li> </ul>"},{"location":"06_engineering_standards/#8-ai-for-data-quality-pattern-detection","title":"8\ufe0f\u20e3 AI for Data Quality Pattern Detection","text":"<p>Practice: AI-assisted anomaly detection and test suggestion.</p> <p>\u2192 What it is: Use AI to identify unusual data patterns and suggest validation tests.</p> <p>\u2192 How I implemented it (project-specific):</p> <p>AI Used To:</p> <ul> <li>Identify unusual anomalies in delivery timing patterns</li> <li>Suggest additional dbt tests for edge cases</li> <li>Detect inconsistent metric logic across layers</li> </ul> <p>Final Decision:</p> <ul> <li>Human validates business context</li> <li>Domain expert confirms anomaly vs. legitimate pattern</li> <li>Test implementation follows standard validation workflow</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Proactive data quality issue detection.</li> <li>Comprehensive test coverage through AI-suggested edge cases.</li> <li>Maintained data trust through validation rigor.</li> </ul>"},{"location":"06_engineering_standards/#9-governance-first-ai-usage","title":"9\ufe0f\u20e3 Governance-First AI Usage","text":"<p>Practice: Strict controls on AI-generated code and logic.</p> <p>\u2192 What it is: Treat AI as an accelerator, not a source of truth.</p> <p>\u2192 How I implemented it (project-specific):</p> Risk Control Incorrect SQL generation dbt tests + CI validation Insecure logic Code review + PR workflow Metric inconsistency Central semantic layer enforcement Hallucinated transformations Manual verification against raw schema Credential exposure Never share credentials with AI tools <p>\u2192 Why it matters (business impact):</p> <ul> <li>Zero AI-generated code deployed without human validation.</li> <li>Maintained security and governance standards.</li> <li>Protected business logic integrity.</li> </ul>"},{"location":"06_engineering_standards/#productivity-cost-impact","title":"\ud83d\udd1f Productivity &amp; Cost Impact","text":"<p>Practice: Measurable efficiency gains from AI integration.</p> <p>\u2192 What it is: Quantified development acceleration and cost optimization.</p> <p>\u2192 How I implemented it (project-specific):</p> <p>Development Efficiency:</p> <ul> <li>30-50% faster SQL drafting (measured by commit velocity)</li> <li>Faster DAX prototyping (reduced measure development time)</li> <li>Reduced boilerplate writing (dimension/test templates)</li> </ul> <p>Cost Efficiency:</p> <ul> <li>AI-suggested query optimizations reduced compute cost</li> <li>Improved incremental logic reduced warehouse load</li> <li>Refactoring reduced redundant table scans</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Faster project delivery without sacrificing quality.</li> <li>Lower operational costs through optimization.</li> <li>Scalable development approach for future phases.</li> </ul>"},{"location":"06_engineering_standards/#11-limitations-responsible-use","title":"1\ufe0f\u20e31\ufe0f\u20e3 Limitations &amp; Responsible Use","text":"<p>Practice: Transparent boundaries on AI capabilities.</p> <p>\u2192 What it is: Clear guardrails on what AI can and cannot do.</p> <p>\u2192 How I implemented it (project-specific):</p> <p>AI Outputs Are Never Deployed Directly To Production.</p> <p>All Generated Code Must Pass:</p> <ul> <li>dbt tests (generic + singular)</li> <li>CI checks (SQLFluff + build validation)</li> <li>BPA validation (Power BI semantic model)</li> <li>Manual code review by human engineer</li> </ul> <p>Never Exposed to AI:</p> <ul> <li>Snowflake credentials</li> <li>Azure connection strings</li> <li>Production database access tokens</li> <li>Sensitive business logic details</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Maintained security posture and compliance.</li> <li>Prevented AI hallucinations from reaching production.</li> <li>Protected intellectual property and business rules.</li> </ul>"},{"location":"06_engineering_standards/#6-self-service-analytics-20-governance-focused","title":"6. \ud83d\udcca Self-Service Analytics 2.0 (Governance-Focused)","text":""},{"location":"06_engineering_standards/#1-the-ai-generated-analytics-crisis-solution","title":"1\ufe0f\u20e3 The AI-Generated Analytics Crisis &amp; Solution","text":"<p>The Problem: AI Flood of Bad Data</p> <p>GenAI tools (ChatGPT, Power BI Copilot) enable anyone to generate charts instantly \u2014 but without governance, this creates a flood of professional-looking reports with mathematical errors and hallucinated numbers. Traditional self-service democratization without controls leads to metric chaos.</p> <p>The Solution: Data Steward Model</p> <p>Role Evolution: Analysts shift from \"report builders\" to \"data guardians\" who certify semantic layers. This project implements governance-first self-service:</p> <pre><code>- \u2705 Centralized metric definitions prevent conflicting calculations\n- \u2705 Certified semantic layer ensures AI tools consume correct data\n- \u2705 Quality transparency (Verified vs Raw) maintains trust\n- \u2705 RLS + contracts enforce security and schema integrity\n</code></pre> <p>Result: Users self-serve with AI acceleration, but data stewards guarantee accuracy.</p>"},{"location":"06_engineering_standards/#2-certified-semantic-layer-as-control-point","title":"2\ufe0f\u20e3 Certified Semantic Layer as Control Point","text":"<p>Practice: Power BI semantic model as the governed data access layer.</p> <p>\u2192 What it is: Pre-built, tested, certified data model that users consume instead of raw tables.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>Power BI semantic model connected to dbt MARTS layer</li> <li>Pre-defined relationships (star schema)</li> <li>Certified measures with business-validated logic</li> <li>Access controlled through workspace roles</li> <li>RLS enforced at semantic layer, not report level</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Users cannot accidentally create incorrect joins.</li> <li>Metrics remain consistent across all reports.</li> <li>Governance enforced at consumption layer, not source.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#3-centralized-metric-definitions-single-source-of-truth","title":"3\ufe0f\u20e3 Centralized Metric Definitions (Single Source of Truth)","text":"<p>Practice: All KPIs defined once in semantic model and reused everywhere.</p> <p>\u2192 What it is: Measures stored in version-controlled semantic model, not scattered across individual reports.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>40+ measures stored in Power BI semantic model TMDL files</li> <li>Each measure documented with business definition</li> <li>Version controlled through .pbip format in Git</li> <li>dbt intermediate/marts models pre-calculate complex fields</li> <li>Report developers drag-and-drop certified measures</li> </ul> <p>Example:</p> <pre><code>Total Revenue =\nCALCULATE(\n    SUM(Sales[order_total]),\n    Sales[is_verified] = TRUE\n)\n</code></pre> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Zero \"metric drift\" \u2014 Finance and Ops see identical numbers.</li> <li>Clear ownership of each calculation.</li> <li>Changes propagate to all consuming reports automatically.</li> </ul>"},{"location":"06_engineering_standards/#4-role-based-access-data-security-rls-rbac","title":"4\ufe0f\u20e3 Role-Based Access &amp; Data Security (RLS + RBAC)","text":"<p>Practice: Dynamic security without duplicating data or logic.</p> <p>\u2192 What it is: Regional managers see only their state's data through automated RLS.</p> <p>\u2192 How I implemented it (project-specific):</p> <p>Snowflake RBAC:</p> <ul> <li>4 roles: <code>LOADER_ROLE</code>, <code>ANALYTICS_ROLE</code>, <code>REPORTER_ROLE</code>, <code>SYSADMIN</code></li> <li>Least-privilege access enforced</li> <li>MFA required for all roles</li> </ul> <p>Power BI RLS:</p> <ul> <li>Bridge table pattern: <code>dim_security_rls</code> \u2192 <code>dim_rls_bridge</code> \u2192 <code>dim_sellers</code> \u2192 <code>fct_order_items</code></li> <li>User email mapped to access keys</li> <li>Dynamic filtering via <code>USERPRINCIPALNAME()</code> DAX</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Regional managers cannot accidentally see competitor region data.</li> <li>Audit-ready security posture.</li> <li>Scalable: add users by updating security table, not DAX code.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#5-verified-vs-raw-transparency-strategy","title":"5\ufe0f\u20e3 Verified vs Raw Transparency Strategy","text":"<p>Practice: Flag data quality issues instead of hiding them.</p> <p>\u2192 What it is: \"Trust, Don't Trash\" approach \u2014 keep all data but mark quality status.</p> <p>\u2192 How I implemented it (project-specific):</p> <p>dbt Logic:</p> <ul> <li><code>is_verified</code> boolean flag (1 = clean, 0 = has issues)</li> <li><code>quality_issue_reason</code> text field (e.g., \"Ghost Delivery\", \"Missing Photos\")</li> <li>All records retained in MARTS layer</li> </ul> <p>Power BI Logic:</p> <ul> <li>Default visuals filter to <code>is_verified = TRUE</code></li> <li>Dedicated Data Quality Audit page shows flagged records</li> <li>KPI cards display \"At-Risk Revenue\" for unverified transactions</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Finance can reconcile to the penny (nothing is deleted).</li> <li>Operations can investigate and fix root causes (ghost products, etc.).</li> <li>Users trust the numbers because quality is transparent.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#6-data-contracts-between-dbt-and-power-bi","title":"6\ufe0f\u20e3 Data Contracts Between dbt and Power BI","text":"<p>Practice: Explicit schema contracts prevent silent breaking changes.</p> <p>\u2192 What it is: dbt enforces output schema; Power BI fails fast on drift.</p> <p>\u2192 How I implemented it (project-specific):</p> <p>dbt Side:</p> <ul> <li><code>contract.enforced: true</code> in MARTS models</li> <li>Schema defined in YAML with data types</li> <li>Build fails if output doesn't match contract</li> </ul> <p>Power BI Side:</p> <ul> <li>Explicit <code>Table.SelectColumns</code> in Power Query</li> <li>No implicit \"select all columns\" patterns</li> <li>Refresh fails immediately on schema mismatch</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Breaking changes detected at build time, not report refresh time.</li> <li>Zero silent column drift breaking dashboards.</li> <li>Clear error messages when contracts break.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#7-business-user-enablement-drag-and-drop-without-sql","title":"7\ufe0f\u20e3 Business User Enablement (Drag-and-Drop Without SQL)","text":"<p>Practice: Non-technical users can build reports without writing code.</p> <p>\u2192 What it is: Self-service via certified measures and dimensions.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>Star schema relationships pre-configured</li> <li>Measures pre-built and business-validated</li> <li>Dimensions have human-friendly column names (Title Case)</li> <li>Report creators drag fields to canvas</li> <li>No SQL, DAX, or M code required for standard analysis</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>3x faster report creation for business users.</li> <li>Reduced backlog on analytics engineering team.</li> <li>Empowered users without compromising governance.</li> </ul>"},{"location":"06_engineering_standards/#8-guardrails-against-metric-drift","title":"8\ufe0f\u20e3 Guardrails Against Metric Drift","text":"<p>Practice: Central enforcement prevents ad-hoc metric redefinition.</p> <p>\u2192 What it is: Report creators cannot override certified measure logic.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>Measures locked in semantic model (not editable in reports)</li> <li>Report-level measures flagged in BPA scans</li> <li>Code review enforces semantic model updates over report-level measures</li> <li>Documentation clarifies when to request semantic model changes</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Prevents \"shadow metrics\" that diverge from certified definitions.</li> <li>Maintains metric consistency across teams.</li> <li>Clear escalation path for new metric requests.</li> </ul>"},{"location":"06_engineering_standards/#9-data-dictionary-built-in-documentation","title":"9\ufe0f\u20e3 Data Dictionary &amp; Built-In Documentation","text":"<p>Practice: Self-documenting semantic model.</p> <p>\u2192 What it is: Every measure and column has inline description visible to users.</p> <p>\u2192 How I implemented it (project-specific):</p> <ul> <li>Power BI measure descriptions stored in semantic model</li> <li>dbt column descriptions auto-generated in docs site</li> <li>Dedicated Documentation page in Power BI with metric definitions</li> <li>Links to external docs (data dictionary, architecture)</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Users understand what metrics mean without asking analysts.</li> <li>Reduced \"What does this field mean?\" questions by 80%.</li> <li>Self-service with confidence.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#trust-indicators-data-freshness-quality-badges","title":"\ud83d\udd1f Trust Indicators (Data Freshness &amp; Quality Badges)","text":"<p>Practice: Explicit transparency on data state.</p> <p>\u2192 What it is: Dashboard footer displays when data was last refreshed and current-through date.</p> <p>\u2192 How I implemented it (project-specific):</p> <p>Dual-Clock Architecture:</p> <ul> <li>Last Refreshed: System time (when dbt pipeline ran)</li> <li>Data Current Until: Business data timestamp (max order date in source)</li> </ul> <p>Quality Indicators:</p> <ul> <li>Tooltip on KPI cards shows \"Verified %\" and \"At-Risk $\"</li> <li>Visual cue when data quality drops below threshold</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Zero confusion about data freshness.</li> <li>Users know instantly if viewing \"yesterday's data\" or \"last month's data\".</li> <li>Trust maintained through transparency.</li> </ul> <p></p>"},{"location":"06_engineering_standards/#11-governance-controls-in-cicd","title":"1\ufe0f\u20e31\ufe0f\u20e3 Governance Controls in CI/CD","text":"<p>Practice: Quality gates before promotion to production.</p> <p>\u2192 What it is: Automated checks prevent low-quality semantic models from reaching users.</p> <p>\u2192 How I implemented it (project-specific):</p> <p>CI Pipeline:</p> <ul> <li>dbt build + test execution</li> <li>BPA scan on semantic model</li> <li>Failed checks block merge</li> </ul> <p>Pre-Production Validation:</p> <ul> <li>UAT testing before prod promotion</li> <li>Revenue reconciliation test between dev and prod</li> <li>Performance validation (load time &lt; 2s)</li> </ul> <p>\u2192 Why it matters (business impact):</p> <ul> <li>Self-service without compromising quality.</li> <li>Governance enforced automatically, not manually.</li> <li>Prevents users from accessing broken semantic models.</li> </ul>"},{"location":"06_engineering_standards/#12-data-steward-as-guardian-of-truth","title":"1\ufe0f\u20e32\ufe0f\u20e3 Data Steward as Guardian of Truth","text":"<p>Practice: Analyst role shifts from report factory to data certification.</p> <p>\u2192 What it is: Respond to AI-generated analytics flood by certifying semantic layers, not building individual reports.</p> <p>\u2192 How I implemented it:</p> Old Model (Report Factory) New Model (Data Steward) Ad-hoc report requests Certify semantic model once Build SQL + Power BI for each ask Users self-serve from certified layer Linear scaling (more requests = hire) Maintains metric accuracy + quality rules <p>\u2192 Why it matters:</p> <p>Scalable analytics without headcount growth. When marketing uses AI to generate charts, they consume pre-validated data. Steward prevents \"hallucinated metrics\" from reaching stakeholders.</p> <p>Modern Data Professional Value</p> <p>\"Anyone can generate a chart with AI. Your value is ensuring the numbers are correct.\"</p>"},{"location":"06_engineering_standards/#7-scalability-reusability-architecture","title":"7. \ud83d\ude80 Scalability &amp; Reusability Architecture","text":""},{"location":"06_engineering_standards/#1-reusable-assets-inventory","title":"1\ufe0f\u20e3 Reusable Assets Inventory","text":"<p>10 Core Reusable Components</p> <p>Infrastructure &amp; Ingestion:</p> <pre><code>1. Raw data in Azure Blob / Snowflake (ingestion pipelines)\n2. Staging models (`stg_*`) in dbt (type-safe source abstraction)\n\n**Transformation Assets:**\n\n3. Dimension models (`dim_customer`, `dim_date`, `dim_product`, `dim_sellers`)\n4. Common intermediate models (`int_orders_enriched`, `int_customers_aggregated`)\n5. dbt tests, docs, exposures, sources, macros (quality framework)\n\n**Consumption Layer:**\n\n6. Semantic layer (Power BI dataset with certified measures)\n7. Power BI semantic model (shared dataset mode for thin reports)\n\n**DevOps &amp; Governance:**\n\n8. Git repo + branch strategy (version control and CI/CD)\n9. CI/CD pipelines (GitHub Actions for dbt validation)\n10. Data contracts &amp; catalog (schema enforcement and lineage)\n</code></pre> <p>\u2192 Impact: New projects start 70% complete by reusing existing assets.</p>"},{"location":"06_engineering_standards/#2-design-philosophy","title":"2\ufe0f\u20e3 Design Philosophy","text":"<p>\u2192 Principle: Invest in reusable assets, not one-off reports.</p> <p>\u2192 Traditional: Each report duplicates logic. Changes = update every report.</p> <p>\u2192 Modern: Centralized transformations. Change once, propagate everywhere.</p> <p>\u2192 Impact: 10x faster report creation, maintainable at scale.</p>"},{"location":"06_engineering_standards/#3-modular-elt-architecture","title":"3\ufe0f\u20e3 Modular ELT Architecture","text":"<p>\u2192 What it is: Strict layer separation enables reuse at every stage.</p> <p>\u2192 How implemented:</p> Layer Purpose Reuse Pattern RAW Immutable source Never transformed STAGING Type casting, standardization Multiple intermediate models consume INTERMEDIATE Business logic, joins Feeds multiple facts (<code>fct_orders</code>, <code>fct_order_items</code>) MARTS Star schema Dimensions reused across all facts <p>\u2192 Why it matters: Change logic once, propagates everywhere. New facts reuse existing staging/intermediate.</p> <p></p>"},{"location":"06_engineering_standards/#4-intermediate-layer-as-building-blocks","title":"4\ufe0f\u20e3 Intermediate Layer as Building Blocks","text":"<p>\u2192 What it is: Pre-joined datasets consumed by multiple marts.</p> <p>\u2192 How implemented: <code>int_orders_enriched</code> (payment + customer + product joins) feeds both <code>fct_orders</code> and <code>fct_order_items</code>. No join duplication.</p> <p>\u2192 Why it matters: Consistent logic, faster queries, single update point.</p>"},{"location":"06_engineering_standards/#5-incremental-processing","title":"5\ufe0f\u20e3 Incremental Processing","text":"<p>\u2192 What it is: Delta-only processing vs full rebuilds.</p> <p>\u2192 How implemented:</p> <ul> <li>dbt: <code>fct_order_items</code> incremental with <code>unique_key</code>, boundary = <code>MAX(order_date_dt)</code></li> <li>Power BI: 10-year rolling window, 1-month refresh grain</li> <li>Only recent data refreshed during daily updates</li> </ul> <p>\u2192 Why it matters: 82% faster refresh (8 min vs 45 min), lower compute costs, scalable to 10x volume.</p> <p></p>"},{"location":"06_engineering_standards/#6-surrogate-key-standardization","title":"6\ufe0f\u20e3 Surrogate Key Standardization","text":"<p>\u2192 What it is: Deterministic keys via <code>dbt_utils.generate_surrogate_key()</code>.</p> <p>\u2192 How implemented:</p> <pre><code>{{ dbt_utils.generate_surrogate_key(['customer_id']) }} as customer_sk\n</code></pre> <p>All dimensions have <code>_sk</code>, all facts reference via <code>_sk</code> FK.</p> <p>\u2192 Why it matters: Predictable joins, supports SCD Type 2, consistent semantic model.</p>"},{"location":"06_engineering_standards/#7-golden-dataset-pattern","title":"7\ufe0f\u20e3 Golden Dataset Pattern","text":"<p>\u2192 What it is: One certified semantic model \u2192 many thin reports.</p> <p>\u2192 How implemented: dbt MARTS \u2192 Power BI semantic model (published) \u2192 Multiple reports reference same model. Reports = visuals only, no transformations.</p> <p>\u2192 Why it matters: Consistent metrics, 5x faster report creation, changes propagate automatically.</p>"},{"location":"06_engineering_standards/#8-thin-reports-architecture","title":"8\ufe0f\u20e3 Thin Reports Architecture","text":"<p>\u2192 What it is: Reports = visualization only. No Power Query, no report-level DAX.</p> <p>\u2192 How implemented: Reports reference certified semantic model. Developers focus on UX, not data prep.</p> <p>\u2192 Why it matters: Faster performance, easier troubleshooting, scalable governance.</p>"},{"location":"06_engineering_standards/#9-environment-separation","title":"9\ufe0f\u20e3 Environment Separation","text":"<p>\u2192 What it is: Dev mirrors prod for safe testing.</p> <p>\u2192 How implemented:</p> <ul> <li>Snowflake: <code>OLIST_DEV_DB</code> vs <code>OLIST_ANALYTICS_DB</code>, switch via <code>--target</code></li> <li>Power BI: Dev workspace vs Prod workspace with parameters</li> </ul> <p>\u2192 Why it matters: Zero prod outages, deployment confidence, fast rollback.</p>"},{"location":"06_engineering_standards/#calculation-groups-for-time-intelligence","title":"\ud83d\udd1f Calculation Groups for Time Intelligence","text":"<p>\u2192 What it is: Define time calculations (YTD, YoY, MoM) once, apply to any measure.</p> <p>\u2192 How implemented: Base measures without time logic. Calculation group applies dynamically.</p> <p>\u2192 Why it matters: Define once, reuse for 40+ measures. No duplication, consistent time logic.</p>"},{"location":"06_engineering_standards/#8-related-documentation","title":"8. Related Documentation","text":"<ul> <li>00_business_requirements.md</li> <li>01_architecture.md</li> <li>02_data_dictionary.md</li> <li>03_data_quality.md</li> <li>04_semantic_model.md</li> <li>05_performance_optimization.md</li> <li>07_analytics_insights.md</li> </ul>"},{"location":"07_analytics_insights/","title":"Analytics Insights","text":""},{"location":"07_analytics_insights/#olist-modern-analytics-platform-business-impact-report","title":"\ud83d\udcca Olist Modern Analytics Platform \u2014 Business Impact Report","text":""},{"location":"07_analytics_insights/#1-executive-summary","title":"1. Executive Summary","text":"<p>The Transformation: This project successfully transformed Olist\u2019s fragmented, manual reporting processes into a fully automated Modern Analytics Platform. By migrating from legacy ad-hoc spreadsheets to a certified Snowflake + dbt + Power BI architecture, we established a Single Source of Truth that reduced reporting latency by 90% (from days to seconds).</p> <p>The Critical Insight: The new platform immediately surfaced a critical correlation: while total verified revenue reached R$13M with strong year-over-year growth, the most recent month saw a -3.4% revenue dip. Drill-down analysis revealed the root cause: an 8.1% delivery delay rate, specifically concentrated in the South region.</p> <p>The Business Impact: This insight identified R$1.2M in \"At-Risk\" revenue tied to logistics bottlenecks. By shifting from reactive reporting to proactive monitoring, Olist leadership can now pivot logistics strategies immediately to recover lost margin, while the engineering automation saves an estimated 20+ hours per week of manual data wrangling.</p>"},{"location":"07_analytics_insights/#2-business-impact-snapshot-before-vs-after","title":"2. Business Impact Snapshot (Before vs After)","text":"<p>\ud83d\udccc Portfolio Context: This project demonstrates enterprise-grade analytics engineering using Olist's public dataset (2016-2018). Impact metrics represent projected business value based on industry benchmarks and showcase understanding of how modern data platforms drive ROI. Technical performance metrics (load times, cost optimizations, test coverage) are measured and reproducible. This framework is designed to be production-ready and demonstrates capabilities that would deliver these outcomes in a live business environment.</p>"},{"location":"07_analytics_insights/#21-architecture-evolution-legacy-vs-modern","title":"2.1 Architecture Evolution (Legacy vs. Modern)","text":"<p>The transformation from a fragmented, manual process to a cloud-native automated platform.</p> Architecture Domain Legacy State (Pain Points) \u274c Modern State (Solution) \u2705 Data Storage Siloed OLTP (Postgres); heavy read-load slowed down the app. Centralized OLAP (Snowflake); optimized for analytical queries. Ingestion Pipeline Manual CSV extracts and ad-hoc scripts; frequent failures &amp; stale data. ELT Pipeline (Snowflake + dbt); distinct \"Raw\" vs. \"Curated\" zones. Data Modeling No defined schema; massive \"Spaghetti SQL\" queries joined at runtime. Kimball Star Schema modeled in dbt with version control &amp; testing. Governance \"Metric Drift\": Every department calculated \"Revenue\" differently. Single Source of Truth: Metrics defined once in Semantic Model and reused everywhere. Scalability Low: System crashes with high volume; manual fixes required. High: Cloud-native architecture scales compute instantly for millions of rows."},{"location":"07_analytics_insights/#22-business-value","title":"2.2 Business Value","text":"<p>3 Transformational Dimensions: Operational Efficiency \u2022 Trust &amp; Governance \u2022 Strategic Insights</p>"},{"location":"07_analytics_insights/#1-operational-efficiency-speed-performance","title":"1\ufe0f\u20e3 Operational Efficiency (Speed &amp; Performance)","text":"<p>Problem: Legacy SQL queries took 30-45 seconds to execute; Stakeholders waited 3-5 days for manual Excel merges; On-premise infrastructure couldn't scale.</p> Metric Before State \u274c After State (Architecture) \u2705 Impact / ROI \ud83d\udcc8 Query Latency 30-45 seconds (Direct SQL queries on legacy system). &lt; 1.2 seconds (Import Mode + Star Schema + Optimized DAX); Performance Analyzer validation: all visuals &lt;1200ms. Reduced report latency by 93% (45s\u21923s); dashboard load &lt;2s; sub-second visual rendering enables flow-state analysis. Data Freshness Weekly/Monthly manual Excel exports; 3-5 day decision latency. Daily @ 06:00 UTC (Automated ELT Pipeline: Azure Blob \u2192 Snowflake \u2192 dbt); Failure alerts via GitHub Actions. Stakeholders make decisions on yesterday's data instead of last week's data (90% faster). Engineering Time 4-6 hours per ad-hoc report; business logic duplicated across analysts. Self-Service: Certified Star Schema + reusable dbt staging/marts models + Power BI semantic model; drag-and-drop trusted measures. Saves 35-45 analyst hours/week (projected); faster onboarding; reduced technical debt via single source of logic. Data Storage &amp; Refresh On-prem storage with manual backups; full daily refresh (45+ min) disrupted business hours. Azure Blob lifecycle policies (Hot\u2192Cool\u2192Archive) + Incremental Refresh on <code>fct_order_items</code> ; 8 min refresh. 60% storage cost reduction + 82% faster refresh time; enabled hourly refresh windows; scalable to 10x data volume."},{"location":"07_analytics_insights/#2-trust-data-governance-the-golden-standard","title":"2\ufe0f\u20e3 Trust &amp; Data Governance (The \"Golden Standard\")","text":"<p>Problem: Finance and Ops had different numbers for \"Revenue\" due to hidden filtering logic (e.g., cancelled orders); All users had full database access; Bad data broke reports.</p> Feature Legacy Approach \u274c Modern Approach \u2705 Governance Win \ud83d\udee1\ufe0f Metric Logic Hidden in Excel formulas or custom SQL; scattered documentation outdated within weeks. Centralized Measures: 40+ measures stored in version-controlled TMDL files (Power BI Projects); Single Source of Truth via dbt Marts &amp; Power BI Semantic Layer. 100% metric consistency across teams; [Total Revenue] definition locked and consistent across all reports; clear ownership of each calculation. Data Quality Bad rows (negative prices, impossible dates) silently deleted; numbers didn't match source; \"phantom\" inventory caused cancelled orders. \"Trust, Don't Trash\" Strategy: dbt applies specific flags:\u2022 Master Flag: <code>is_verified</code> (1/0) for clean/dirty filtering\u2022 Diagnostic: <code>quality_issue_reason</code> (e.g., \"Ghost Delivery\", \"Missing Photos\", \"Arrival Before Approval\") 100% traceability: Finance reconciles exact penny amounts including \"Revenue at Risk\"; actionable correction lists (609 products with missing photos flagged). Security Single SYSADMIN role; shared credentials; everyone sees everything; no audit trail. Snowflake RBAC: 4 roles (LOADER, ANALYTICS, REPORTER) + Power BI RLS via Bridge Table restricts managers to their specific State/Region + MFA enforced. Audit-ready security posture; enforces least-privilege access automatically via user login; compliance with data governance policies."},{"location":"07_analytics_insights/#3-strategic-insights-new-capabilities","title":"3\ufe0f\u20e3 Strategic Insights (New Capabilities)","text":"<p>Problem: We knew what sold, but not who bought it or why it arrived late; No visibility into regional bottlenecks or product quality issues; Static customer lists.</p> Business Question Previously Impossible \u274c Now Possible \u2705 Strategic Value \ud83d\udca1 Retention Strategy Could not link orders to unique humans over time; static Excel lists. Cohort Analysis: <code>order_sequence_number</code> (calculated in dbt via Window Functions) identifies New vs Repeat patterns on any historic date. LTV Optimization: Marketing shifts spend from \"User Acquisition\" to \"Retention\" campaigns based on live Repeat Purchase Rate data. Logistics Diagnostics \"Average Delivery Time\" hid outliers; reactive complaint handling. Root Cause Decomposition: Decomposition Tree in Power BI exposes states with &gt;20% delay rates (Amazonas: 66.7% failure vs. S\u00e3o Paulo: 8.8%). SLA Enforcement: Surfaced R$1.2M revenue at risk in Northern region; Ops can delist specific underperforming sellers to protect brand reputation. Product Quality Management 610 products with missing photos went unnoticed; \"invisible inventory\" caused lost sales. Automated dbt tests flag incomplete product records; Ops team alerted when \"At Risk\" revenue &gt;R$10K. Detects R$11K+ at-risk revenue monthly; proactive catalog management prevents lost sales. Seller Performance Tracking No centralized scorecard; difficult to spot partners causing delivery bottlenecks. Performance Grid: Sellers ranked by Revenue and Risk (is_delayed). RLS Bridge allows regional managers to view specific partners. Operations Efficiency: Ops teams instantly pinpoint underperforming sellers driving up Delay Rates."},{"location":"07_analytics_insights/#23-technical-maturity-engineering-excellence","title":"2.3 Technical Maturity \u2014 Engineering Excellence","text":"<p>4 Pillars of Production-Ready Systems: DataOps &amp; CI \u2022 Quality &amp; Resilience \u2022 Performance &amp; Cost \u2022 Observability &amp; UX</p>"},{"location":"07_analytics_insights/#1-software-engineering-standards-dataops-ci","title":"1\ufe0f\u20e3 Software Engineering Standards (DataOps &amp; CI)","text":"<p>Problem: \"Works on my machine.\" Developing directly in Production; breaking changes deployed without validation; Binary .pbix files prevented code reviews.</p> Component Junior Approach \u274c Senior Approach \u2705 Engineering Win \ud83d\udd27 Development Workflow Developing directly in Production; changes went live immediately without validation; no documented process. ADLC Framework: Dev/Prod separation; separate Power BI workspaces; UAT validation before Prod promotion; GitHub Issues tracking; structured manual guide using ADLC framework in Notion. Zero downtime deployments; 100% UAT pass rate before Prod; zero broken reports; instant rollback via Git; repeatable processes documented for team onboarding. Version Control Binary .pbix files in SharePoint; \"Save As\" versioning. Power BI Projects (.pbip): JSON-based semantic model stored in Git; full change history; diff tracking; parallel development via PRs. Granular version history; code reviews for DAX measures; blame tracking for debugging; Git Diffs enable logic reviews. CI Pipeline Manual dbt runs; deployed broken models to Prod; no automated checks. GitHub Actions CI: SQLFluff linting, dbt build with tests, BPA scans, pre-commit hooks that check files best practices before it hits git(SQLFluff auto-fix), auto-deploy on merge to main. 100% test coverage enforcement; pre-commit hooks catch SQL issues before commit; CI blocks merges with failing tests. AI-Assisted Development Manual coding from scratch; context lost between sessions; inconsistent AI responses. Structured AI workflow: GitHub Copilot for dbt SQL; <code>agents.md</code> defines personas (Analytics Engineer, BI Developer); <code>prompt.md</code> files stores project context; dedicated ChatGPT session given full context of project. 2x development velocity; consistent AI output quality; AI remembers project architecture and business rules; reduces context re-explaining."},{"location":"07_analytics_insights/#2-quality-assurance-resilience","title":"2\ufe0f\u20e3 Quality Assurance &amp; Resilience","text":"<p>Problem: Manual visual checks; data quality issues found by users after dashboards broke; No backup strategy; Breaking changes deployed without warning.</p> Component Legacy Reality \u274c Production-Ready Solution \u2705 Reliability Gain \ud83d\udee1\ufe0f Automated Testing Manual visual checks; data quality issues found by users after dashboards broke. Testing Pyramid: dbt (150+ tests: 60% source, 30% generic, 10% singular tests) + BPA Scans + CI pipeline validation. Catches 100% of FK violations before merge; prevents bad data from reaching dashboards; business rules enforced in code. Schema Evolution Breaking changes deployed without warning; Power Query implicitly loaded all columns. dbt schema contracts + data validation in staging; explicit <code>Table.SelectColumns</code> in Power Query to prevent schema drift; change impact analysis before merge. Zero breaking changes in Prod; prevents schema drift; fails fast at refresh with clear error messages; explicit contract between Snowflake and Power BI. Disaster Recovery No backup strategy; estimated 72+ hours to rebuild from scratch. Azure Blob geo-redundant storage + Snowflake Time Travel (90 days) + Git history + automated snapshots. RPO: &lt;1 hour, RTO: &lt;15 minutes; disaster recovery architecture ensures rapid recovery; business continuity framework established. Data Lineage \"Where does this number come from?\" required hours of investigation. dbt Docs DAG: Full lineage from RAW table \u2192 staging \u2192 intermediate \u2192 marts \u2192 Power BI exposure; auto-generated documentation; ADLC framework in repo. Instant root cause analysis; trust in data transformation logic; clear ownership of each layer; 90% faster onboarding for new engineers."},{"location":"07_analytics_insights/#3-performance-cost-optimization-datafinops","title":"3\ufe0f\u20e3 Performance &amp; Cost Optimization (DataFinOps)","text":"<p>Problem: Full daily refresh of all tables; uncontrolled query execution; no budget monitoring; Nested views (10+ layers deep) made debugging impossible.</p> Component Wasteful Pattern \u274c Optimized Strategy \u2705 Cost &amp; Speed Benefit \ud83d\udcb0 Compute Optimization Full daily refresh of all tables; uncontrolled query execution; no budget monitoring. Incremental refresh in dbt on fct_order_items (<code>unique_key</code>) + Power BI (Sales) Table; X-SMALL warehouses with auto-suspend (60s); query tagging for cost attribution. Reduced Snowflake compute costs by 42%; cost attribution per team; auto-suspend prevents idle waste. Query Optimization No query profiling; users complained about slow dashboards; transformations scattered across layers. Shift-Left: Heavy Math calculations (datediff) moved to Snowflake; aggregations moved to Power BI; query folding in Power Query pushes transformations to Snowflake; Performance Analyzer validation before publishing report all visuals load under &lt;1200ms. Lowest compute cost in Snowflake; fastest rendering for users; query latency improved 5x; dashboard load &lt;2s. Data Transformation Nested views in PostgreSQL (10+ layers deep); scattered Word docs; outdated within weeks. dbt Medallion Architecture (RAW\u2192STAGING\u2192INTERMEDIATE\u2192MARTS) + auto-generated dbt Docs with live lineage graphs; reusable intermediate models + full lineage of BI assets via Power BI Service Task Flow + Semantic Model Documentation. 90% faster onboarding; clear lineage; documentation stays in sync with code; prevents \"view spaghetti\" anti-pattern."},{"location":"07_analytics_insights/#4-observability-user-experience","title":"4\ufe0f\u20e3 Observability &amp; User Experience","text":"<p>Problem: Stakeholders confused why data seemed stale despite \"Refresh successful\" messages; KPI cards showed only headline numbers; Raw column names confused business users.</p> Component User Frustration \u274c Transparency Solution \u2705 UX Improvement \ud83d\udc65 Dashboard Observability Stakeholders confused why data seemed stale despite \"Refresh successful\" messages; frequent \"Is the data up to date?\" emails. Dual-Timestamp Architecture: Separation of concerns in Dashboard Header:\u2022 \ud83c\udf25\ufe0f Last Refreshed: System Time (dbt pipeline run transformed new data )\u2022 \ud83d\uddc4\ufe0f Data Current Until: Data Time (Max timestamp from Snowflake <code>meta_project_status</code>) Zero confusion. Executives know instantly if viewing \"Today's Data\" vs. \"Most recent ELT run\", distinguishing pipeline latency from report refresh latency. Data Health Monitoring Issues found when users reported broken dashboards; no visibility into pipeline health. Snowflake resource monitors + dbt freshness checks + Power BI refresh failure alerts + dedicated Data Quality &amp; Integrity Audit page. Proactive issue detection; Ops team sees at-risk SKUs (610 missing photos, R$11K revenue at risk) before impacting sales. User Experience KPI cards showed only headline numbers; raw column names (snake_case) exposed in Power BI; confusing for business users. Tooltip implementation (Verified %, At-Risk $) + dual-timestamp footer + dedicated Documentation page + renamed columns to Title Case (e.g., <code>order_status</code> \u2192 \"Order Status\"). Users verify data quality without leaving dashboard; new users onboard 3x faster; business-friendly UI; non-technical users understand fields; eliminates \"silent failures\"."},{"location":"07_analytics_insights/#3-strategic-insights-recommendations","title":"3. Strategic Insights &amp; Recommendations","text":"<p>3 Critical Business Opportunities Uncovered via Data Analysis</p>"},{"location":"07_analytics_insights/#insight-1-the-north-region-logistics-failure","title":"\ud83d\udd34 Insight 1 \u2013 The \"North Region\" Logistics Failure","text":"<ul> <li>Insight: While the national delivery network is stable, the Northern region is experiencing a critical failure rate, effectively alienating an entire geographic market.</li> <li>Evidence: The Root Cause Decomposition Tree highlights that Amazonas (AM) has a 66.7% Delivery Failure Rate, and Maranh\u00e3o (MA) is at 23.1%. This contrasts sharply with the healthy 8.8% rate in S\u00e3o Paulo.</li> <li>Impact: High operational costs due to refunds/returns in the North, plus negative brand reputation preventing future growth in that territory.</li> <li>Recommendation: Immediate courier review for the North. Switch logistics partners for interstate deliveries to AM/MA and extend the \"Estimated Delivery Date\" in the app for these specific zip codes to manage expectations.</li> </ul>"},{"location":"07_analytics_insights/#insight-2-the-empty-calorie-growth-volume-vs-value","title":"\ud83d\udfe0 Insight 2 \u2013 The \"Empty Calorie\" Growth (Volume vs. Value)","text":"<ul> <li>Insight: The business is acquiring more customers, but they are becoming less valuable. We are seeing \"Empty Calorie\" growth.</li> <li>Evidence: Month-over-Month Order Volume increased by +3.1% (96K orders), yet Total Revenue dropped by -3.4%. This is driven by a -6.3% drop in Average Order Value (AOV).</li> <li>Impact: Profit margins are shrinking. We are processing more shipments (higher cost) for less revenue (lower return).</li> <li>Recommendation: Shift marketing spend from \"low-ticket\" items (likely \"Cool Stuff\" or \"Auto\") to high-AOV categories like \"Computers\" or \"Watches.\" Launch product bundles (e.g., \"Buy 2, Save 10%\") to artificially inflate AOV.</li> </ul>"},{"location":"07_analytics_insights/#insight-3-revenue-at-risk-via-invisible-inventory","title":"\ud83d\udfe1 Insight 3 \u2013 Revenue at Risk via \"Invisible\" Inventory","text":"<ul> <li>Insight: A lack of validation in the seller portal is causing \"Silent Revenue Loss.\" Products are listed but unsellable due to data errors.</li> <li>Evidence: The Data Quality Audit identified 1.85% of the Catalog as \"High Risk,\" primarily due to 610 SKUs with Missing Photos. Additionally, R$11,347 in revenue is flagged as \"At Risk\" due to system logic failures.</li> <li>Impact: We are losing sales on 610 products simply because customers won't buy items they can't see.</li> <li>Recommendation: Implement a \"Hard Stop\" in the Seller Portal: Sellers cannot publish a listing without at least 1 uploaded photo. Create an automated dbt alert for the Operations team when \"At Risk\" revenue exceeds R$10k.</li> </ul>"},{"location":"07_analytics_insights/#6-key-business-questions-evidence-answers","title":"6. Key Business Questions \u2014 Evidence &amp; Answers","text":""},{"location":"07_analytics_insights/#q1-how-are-total-revenue-and-order-volume-trending-over-time","title":"\u2753 Q1: How are total revenue and order volume trending over time?","text":"<ul> <li>Question: \"What is the total revenue and volume performance, and how is it trending?\"</li> <li>Answer: \"Total verified Revenue reached R$13M with a total volume of 96K Orders. While the long-term trend shows consistent growth from Jan 2017 to mid-2018, the most recent month shows a divergence: Order Volume increased by +3.1%, but Revenue dipped by -3.4%.\"</li> <li>Visual Used: KPI Cards (Top Row) &amp; Trend Line Chart (Revenue Bars vs. Order Line).</li> <li>What it means: \"The drop in revenue despite rising order counts is explained by the -6.3% drop in Average Order Value (AOV). Customers are buying more often, but purchasing lower-value items this month. Additionally, the tooltip reveals that 99.9% of this revenue is Verified (Delivered), with only 0.1% at risk.\"</li> </ul>"},{"location":"07_analytics_insights/#q2-which-product-categories-generate-the-most-revenue-and-orders","title":"\u2753 Q2: Which product categories generate the most revenue and orders?","text":"<ul> <li>Question: \"Which product categories are the primary drivers of business volume?\"</li> <li>Answer: \"Bed Bath Table is the absolute volume leader with 9.3K orders. It is followed by Health Beauty (8.6K) and Sports Leisure (7.5K).\"</li> <li>Visual Used: Horizontal Bar Chart (\"Top 10 Products by Total Orders\").</li> <li>What it means: \"The marketplace is dominated by Home &amp; Lifestyle goods rather than Electronics. The top 3 categories account for a significant portion of volume, meaning inventory stability in 'Bed Bath Table' is critical for monthly targets.\"</li> </ul>"},{"location":"07_analytics_insights/#q3-which-regions-and-states-contribute-most-to-revenue-and-orders","title":"\u2753 Q3: Which regions and states contribute most to revenue and orders?","text":"<ul> <li>Question: \"Where is our customer base geographically concentrated?\"</li> <li>Answer: \"S\u00e3o Paulo (SP) is the single largest market, driving 40K orders (approx. 41% of total volume). Rio de Janeiro (RJ) and Minas Gerais (MG) follow with 12K and 11K respectively.\"</li> <li>Visual Used: Treemap (\"Total Orders Distribution by State\").</li> <li>What it means: \"The business is heavily concentrated in the Southeast region. Success in S\u00e3o Paulo effectively dictates the success of the entire company. Any logistics bottleneck in SP (the largest block) will have a disproportionate impact on global KPIs compared to smaller states like SC or PR.\"</li> </ul>"},{"location":"07_analytics_insights/#q4-how-efficient-is-order-delivery-performance-across-regions","title":"\u2753 Q4: How efficient is order delivery performance across regions?","text":"<ul> <li>Question: \"What is the baseline for logistics efficiency, and where are the bottlenecks?\"</li> <li>Answer: \"The network operates with an average delivery time of 12.4 days and an overall Delay Rate of 8.1%. While the 91.9% On-Time Rate appears healthy at a macro level, deep disparities exist at the regional level.\"</li> <li>Visual Used: KPI Cards &amp; Root Cause Analysis (Decomposition Tree).</li> <li>What it means: \"The Decomposition Tree highlights that delays are not random; they are geographic. Northern states face severe logistics failures, with Amazonas (AM) seeing a 66.7% failure rate and Maranh\u00e3o (MA) at 23.1%. In contrast, high-volume states like SP maintain an 8.8% delay rate, suggesting the problem is specific to 'Last Mile' carriers in remote regions.\"</li> </ul>"},{"location":"07_analytics_insights/#q5-which-sellers-contribute-the-most-to-revenue","title":"\u2753 Q5: Which sellers contribute the most to revenue?","text":"<ul> <li>Question: \"Where is our supply-side revenue concentrated?\"</li> <li>Answer: \"Sellers based in S\u00e3o Paulo (SP) are the absolute engine of the marketplace, generating R$84.8M in revenue across 68K orders. No other state comes close; the next largest contributor is MG (Minas Gerais) with significantly lower volume.\"</li> <li>Visual Used: \"Seller State\" Matrix Table (Bottom Left).</li> <li>What it means: \"The platform has a Single Point of Failure risk. Since &gt;65% of revenue originates from sellers in SP, any local disruption there (strikes, weather, tax changes) would cripple the entire platform's Gross Merchandise Value (GMV). Diversifying the seller base into Southern states (PR, SC) is a necessary strategic move.\"</li> </ul>"},{"location":"07_analytics_insights/#q6-how-many-customers-are-repeat-buyers-versus-new-customers","title":"\u2753 Q6: How many customers are repeat buyers versus new customers?","text":"<ul> <li>Question: \"Are we building a loyal customer base or just acquiring new ones?\"</li> <li>Answer: \"The business is currently fueled almost entirely by new acquisition. The Loyalty Rate is only 3.0%, meaning 97% of customers purchase once and never return.\"</li> <li>Visual Used: KPI Card &amp; \"Customer Retention Trend\" Stacked Column Chart.</li> <li>What it means: \"The Trend Chart shows strong growth in New Customers (Light Blue bars), but the Repeat Customers segment (Dark Blue bars) is barely visible. This indicates a classic 'Leaky Bucket' problem. While Marketing is effective at acquisition, the operational experience (likely the 12-day wait time) is preventing users from becoming loyalists. Improving retention from 3% to 5% would likely be more profitable than acquiring 1,000 new users.\"</li> </ul>"},{"location":"designs/003_marts_star_schema/","title":"Design Notes","text":""},{"location":"designs/003_marts_star_schema/#design-doc-marts-layer-star-schema-architecture","title":"\ud83d\udcc4 Design Doc: Marts Layer &amp; Star Schema Architecture","text":"<p>Author: Ayan Mulaskar Status: \ud83d\udfe2 Approved for Implementation Phase: Phase 4 (Marts &amp; Consumption) Related Issue: [FEAT] Phase 4: Marts Layer Implementation</p>"},{"location":"designs/003_marts_star_schema/#1-context-business-objectives","title":"1. Context &amp; Business Objectives","text":""},{"location":"designs/003_marts_star_schema/#overview","title":"Overview","text":"<p>The transformation of logic-heavy Intermediate models into a high-performance Kimball Star Schema optimized for Power BI Import Mode.</p>"},{"location":"designs/003_marts_star_schema/#business-goal","title":"Business Goal","text":"<p>To enable trusted, sub-second analysis of Revenue, Retention, and Logistics KPIs for the Executive Dashboard, solving the current lack of historical context and \"Lost Revenue\" visibility.</p>"},{"location":"designs/003_marts_star_schema/#problem-statement","title":"Problem Statement","text":"<p>Current reporting relies on normalized, joined-at-runtime tables. This causes:</p> <ul> <li>Slow Performance: Dashboard refreshes take &gt;10s due to complex JOINs.</li> <li>Ambiguous Metrics: No standardized definition for \"Canceled Orders\" (Lost Revenue).</li> <li>Silent Failures: Stakeholders cannot distinguish between \"No Sales Today\" and \"Pipeline Failed.\"</li> </ul>"},{"location":"designs/003_marts_star_schema/#2-scope-constraints","title":"2. Scope &amp; Constraints","text":""},{"location":"designs/003_marts_star_schema/#in-scope","title":"\u2705 In Scope","text":"<ul> <li>Star Schema: Implementation of 1 Fact (<code>fct_order_items</code>) and 4 Conformed Dimensions.</li> <li>Observability: \"Two Clocks\" metadata strategy to decouple Pipeline Health from Data Freshness.</li> <li>Security: Row-Level Security (RLS) via the Bridge Table Pattern to map Managers to Regions.</li> <li>Governance: Schema-level Data Contracts (<code>enforced: true</code>) and downstream Exposures.</li> </ul>"},{"location":"designs/003_marts_star_schema/#out-of-scope","title":"\u274c Out of Scope","text":"<ul> <li>Real-time streaming (Batch frequency is set to Daily).</li> <li>Predictive Analytics / Machine Learning models.</li> <li>Self-Service access to Raw/Staging layers for business users.</li> </ul>"},{"location":"designs/003_marts_star_schema/#3-architecture-data-flow","title":"3. Architecture &amp; Data Flow","text":"<p>Pattern: Dimensional Modeling (Kimball Star Schema)</p> <p>Flow:</p> <pre><code>RAW \u2192 STAGING \u2192 INTERMEDIATE \u2192 MARTS \u2192 Power BI\n</code></pre> <p>Key Principle: Logic happens in INTERMEDIATE. Marts are for scoping, renaming, and star schema alignment.</p>"},{"location":"designs/003_marts_star_schema/#4-detailed-data-model-design","title":"4. Detailed Data Model Design","text":""},{"location":"designs/003_marts_star_schema/#41-system-audit-strategy-the-heartbeat","title":"4.1 System &amp; Audit Strategy (The \"Heartbeat\")","text":"<p>Table: <code>meta_project_status</code> Grain: Singleton (1 Row) Purpose: Solves the \"Frozen Source\" problem inherent in the Olist dataset (Data ends in 2018, but Pipeline runs in 2026).</p> Column Type Purpose <code>pipeline_last_run_at</code> Timestamp Engineering Clock: Proves the dbt pipeline ran successfully today. <code>data_valid_through</code> Date Business Clock: Proves the data context (e.g., \"Data ends Aug 2018\")."},{"location":"designs/003_marts_star_schema/#42-fact-strategy-fct_order_items","title":"4.2 Fact Strategy (<code>fct_order_items</code>)","text":"<p>Source: <code>int_sales__order_items_joined</code></p> <p>Materialization: - Phase : <code>incremental</code> (Append + Update) via <code>dbt_updated_at</code> watermark.</p> <p>Grain: One row per Line Item.</p> <p>Business Logic: Retains ALL order statuses (<code>delivered</code>, <code>canceled</code>, <code>unavailable</code>) to enable \"Lost Revenue\" analysis.</p> <p>Metrics: - <code>price_brl</code> (Gross Revenue) - <code>freight_value_brl</code></p> <p>Quality Flags: - <code>is_verified</code> (Boolean): True if rows meet strict business rules. - <code>quality_issue_reason</code>: Descriptive error for unverified rows (e.g., \"Zero Price\").</p>"},{"location":"designs/003_marts_star_schema/#43-dimension-strategy-conformed","title":"4.3 Dimension Strategy (Conformed)","text":"Dimension Grain Type Key Attributes <code>dim_customers</code> Person Type 1 <code>customer_city</code>, <code>is_repeat_buyer</code> <code>dim_products</code> Product Type 1 <code>category_name_en</code> (Denormalized), <code>product_volume</code> <code>dim_sellers</code> Seller Type 1 <code>seller_city</code>, <code>seller_state_code</code> (RLS Target) <code>dim_date</code> Day Type 0 <code>is_weekend</code>, <code>quarter</code>, <code>year_month_sort</code> <p>Design Decision: All dimensions are Type 1 (overwrite) except <code>dim_date</code> which is Type 0 (static). No history tracking needed for this use case.</p>"},{"location":"designs/003_marts_star_schema/#5-security-implementation-the-bridge-pattern","title":"5. Security Implementation (The Bridge Pattern)","text":""},{"location":"designs/003_marts_star_schema/#challenge","title":"Challenge","text":"<p>A Many-to-Many relationship exists between Managers (Users) and Regions (Data).</p> <ul> <li>One Manager oversees Many States.</li> <li>One State contains Many Sellers.</li> </ul>"},{"location":"designs/003_marts_star_schema/#solution-decoupled-security-model","title":"Solution: Decoupled Security Model","text":"<p>Architecture:</p> <ol> <li><code>dim_security_rls</code>: Maps User Email (<code>alice@olist.com</code>) \u2192 Access Group.</li> <li><code>dim_rls_bridge</code>: Explodes Access Group \u2192 Permitted State Codes.</li> </ol> <p>Power BI Flow:</p> <pre><code>User \u2192 dim_security_rls \u2192 dim_rls_bridge \u2192 dim_sellers \u2192 fct_order_items\n</code></pre> <p>Why Bridge Table? - Prevents Cartesian explosion in the fact table. - Centralizes security logic (add new manager = 1 row in <code>dim_security_rls</code>). - Supports dynamic security (regional manager promoted to national = update access group, not rebuild fact).</p>"},{"location":"designs/003_marts_star_schema/#6-power-bi-readiness-exposures","title":"6. Power BI Readiness &amp; Exposures","text":""},{"location":"designs/003_marts_star_schema/#lineage","title":"Lineage","text":"<p>Defined in <code>models/exposures.yml</code>. Links Marts to the \"Olist Executive Dashboard\" node in the dbt graph.</p>"},{"location":"designs/003_marts_star_schema/#usability","title":"Usability","text":"<p>All Surrogate Keys (<code>_sk</code>) and System Flags (<code>dbt_updated_at</code>) are Hidden in the Power BI Semantic Model to prevent user confusion.</p>"},{"location":"designs/003_marts_star_schema/#performance","title":"Performance","text":"<p>Model strictly enforces One-to-Many relationships, allowing the VertiPaq engine to maximize compression and query speed.</p>"},{"location":"designs/003_marts_star_schema/#7-data-governance-testing","title":"7. Data Governance &amp; Testing","text":""},{"location":"designs/003_marts_star_schema/#71-data-contracts","title":"7.1 Data Contracts","text":"<p>Enforcement: <code>contract: {enforced: true}</code> enabled on all Marts.</p> <p>Benefit: Prevents upstream schema changes (e.g., column renames) from silently breaking the Power BI dashboard.</p>"},{"location":"designs/003_marts_star_schema/#72-testing-strategy-defense-in-depth","title":"7.2 Testing Strategy (Defense in Depth)","text":""},{"location":"designs/003_marts_star_schema/#generic-tests-schema","title":"Generic Tests (Schema)","text":"<ul> <li><code>unique</code>, <code>not_null</code> on all Primary Keys (<code>_sk</code>).</li> <li><code>relationships</code> (Referential Integrity) on all Foreign Keys.</li> </ul>"},{"location":"designs/003_marts_star_schema/#singular-tests-business-logic","title":"Singular Tests (Business Logic)","text":"<ul> <li><code>mart_fct_order_items_metric_ranges</code>: Asserts <code>price_brl &gt;= 0</code>.</li> <li><code>mart_dim_date_completeness</code>: Asserts no missing dates in the 2016-2020 range.</li> <li><code>mart_rls_seller_state_coverage</code>: Asserts all 27 Brazilian states are mapped in RLS.</li> </ul>"},{"location":"designs/003_marts_star_schema/#8-risks-trade-offs","title":"8. Risks &amp; Trade-offs","text":"Decision Alternative Reason for Choice Star Schema One Big Table (OBT) Security: The RLS requirement (filtering Sellers by State) requires a normalized <code>dim_sellers</code> table. OBT would require massive data duplication to support this security model. Surrogate Keys Natural Keys Integrity: Olist <code>customer_id</code> resets per order. Persistent SKs allow us to track Unique Customers across multiple orders. Meta Table LocalNow() in BI Accuracy: Power BI functions only measure report refresh time. The Meta Table accurately measures Data refresh time, preventing \"False Positives\" when pipelines fail."},{"location":"designs/003_marts_star_schema/#9-rollout-plan","title":"9. Rollout Plan","text":"<p>Implementation Steps:</p> <ol> <li>Core Dimensions: Deploy <code>dim_customers</code>, <code>dim_products</code>, <code>dim_sellers</code>, <code>dim_date</code>.</li> <li>Security Layer: Deploy <code>dim_security_rls</code>, <code>dim_rls_bridge</code>.</li> <li>Fact Table: Deploy <code>fct_order_items</code> (Full Refresh).</li> <li>Observability: Deploy <code>meta_project_status</code>.</li> <li>Validation: Run <code>dbt test --select marts</code>.</li> <li>Documentation: Generate Lineage Graph with Exposures.</li> </ol> <p>Rollback Strategy:</p> <p>If issues arise post-deployment, revert to previous git tag and redeploy with <code>dbt build --full-refresh --select marts</code>.</p>"},{"location":"designs/003_marts_star_schema/#10-references","title":"10. References","text":"<ul> <li>Kimball Methodology: The Data Warehouse Toolkit</li> <li>dbt Best Practices: dbt Discourse - Marts Layer</li> <li>Power BI RLS Patterns: Microsoft Docs - Row-Level Security</li> </ul> <p>Last Updated: January 2026 Version: 1.0</p>"}]}